{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Setting Some Ground Rules\n",
    "\n",
    "Theme settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:20.539376Z",
     "start_time": "2021-08-23T01:59:19.971275Z"
    },
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset css and font defaults in:\r\n",
      "/Users/drios/.jupyter/custom &\r\n",
      "/Users/drios/Library/Jupyter/nbextensions\r\n"
     ]
    }
   ],
   "source": [
    "!jt -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generating Dataset\n",
    "\n",
    "*   From Campridge University .xml dataset\n",
    "*   Each .xml file contains data about a student's test\n",
    "*   Information extracted from each .xml file:\n",
    "    *   document name\n",
    "    *   student response\n",
    "    *   number of mistakes\n",
    "    *   the mistakes themselves\n",
    "    *   the corrections\n",
    "    *   correction codes\n",
    "    *   answer score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "hide_input": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"xml_example.png\", alt=\"oops\", style=\"width: 800px;\", align=\"center\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:21.176021Z",
     "start_time": "2021-08-23T01:59:20.542731Z"
    },
    "cell_style": "center",
    "hidden": true,
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2485.xml'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take care of some imports for this section of the notebook\n",
    "\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "from My_Functions import parse_xml\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# changing directory into the one that contains our .xml files\n",
    "os.chdir('/Users/drios/Thinkful/Final_Capstone/XML_Files/Compiled/')\n",
    "\n",
    "# create a list of the xml files we want to parse for dataset generation\n",
    "list_of_xml_files = os.listdir()\n",
    "\n",
    "# let's confirm the first .xml file name, we can compare against the Jupyter local folder\n",
    "list_of_xml_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dataframes generated by iterating through the available .xml files and parsing them for the student answer data using a ```parse_xml()``` function created in another notebok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.149657Z",
     "start_time": "2021-08-23T01:59:21.179384Z"
    },
    "cell_style": "split",
    "hidden": true,
    "hide_input": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fce_df_answer_1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc2485.xml</td>\n",
       "      <td>Dear Helen I have received your letter which m...</td>\n",
       "      <td>[., is, make, The, attempt, invite, holidy, , ...</td>\n",
       "      <td>20</td>\n",
       "      <td>[,, ,, makes, For the, a, take you up on, invi...</td>\n",
       "      <td>[RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1832.xml</td>\n",
       "      <td>Dear Sir, Last week I London for . During my s...</td>\n",
       "      <td>[stayed in, holidays, show, was, see, diferent...</td>\n",
       "      <td>15</td>\n",
       "      <td>[went to, a, holiday, were, seeing, different,...</td>\n",
       "      <td>[RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc426.xml</td>\n",
       "      <td>Dear Helen Ryan: I am writing to answer the qu...</td>\n",
       "      <td>[to, an other, august, rather, log cabins, its...</td>\n",
       "      <td>12</td>\n",
       "      <td>[another, August, a, log cabin, it's, options,...</td>\n",
       "      <td>[UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1826.xml</td>\n",
       "      <td>Dear Sir, I'm writing to you to complain about...</td>\n",
       "      <td>[None, deceiveful, it, into, character, of, ad...</td>\n",
       "      <td>25</td>\n",
       "      <td>[deceitful, disappointing, actor, advertising,...</td>\n",
       "      <td>[RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1198.xml</td>\n",
       "      <td>Dear Sir or Madam, I am writing to complain ab...</td>\n",
       "      <td>[musical, which, it, didn't make us happy, Non...</td>\n",
       "      <td>33</td>\n",
       "      <td>[the, of, what, went wrong, theater, theatre, ...</td>\n",
       "      <td>[UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>doc2311.xml</td>\n",
       "      <td>June 17th, 2000 Dear Sir, I am writing this le...</td>\n",
       "      <td>[whom, am I, starring, of, will, started, enit...</td>\n",
       "      <td>10</td>\n",
       "      <td>[how, I am, ,, acting, for, would, start, it, ...</td>\n",
       "      <td>[R, W, MP, RV, RT, TV, FV, MA, MD, DV, RJ, S, RV]</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>doc2305.xml</td>\n",
       "      <td>Dear Mr Robertson, Thank you for effort which ...</td>\n",
       "      <td>[your, ,, three days, programm, advertisment, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[the, three-day, programme, ,, concerning, adv...</td>\n",
       "      <td>[RD, UP, DJ, S, MP, MT, S, MD, MP, S, RJ, UY, ...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>doc2463.xml</td>\n",
       "      <td>To the manger of the Circle Theatre Mr Smith C...</td>\n",
       "      <td>[a, trip, free-time, for, different, informati...</td>\n",
       "      <td>18</td>\n",
       "      <td>[free time, information, ,, ,, tourists, parts...</td>\n",
       "      <td>[UD, UN, UP, UT, UJ, CN, MP, MP, UD, AGN, AGN,...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>doc365.xml</td>\n",
       "      <td>Dear Mr Brown, I went to the Circle Theatre ye...</td>\n",
       "      <td>[got, only, sign, What, quite not, it, no, dif...</td>\n",
       "      <td>17</td>\n",
       "      <td>[was, That, not quite, one, ,, No, contrary, t...</td>\n",
       "      <td>[RV, UY, UN, RA, W, RA, MP, RP, RY, RT, UN, RA...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>doc403.xml</td>\n",
       "      <td>13.06.2000 Dear Mrs. Ryan, you very much for y...</td>\n",
       "      <td>[thank, have had, None, According to, Accomoda...</td>\n",
       "      <td>16</td>\n",
       "      <td>[Thank, had, according to, because of, Accommo...</td>\n",
       "      <td>[RP, TV, R, RP, S, MD, AGN, RP, SX, R, RY, RP,...</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1244 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "0      doc2485.xml  Dear Helen I have received your letter which m...   \n",
       "1      doc1832.xml  Dear Sir, Last week I London for . During my s...   \n",
       "2       doc426.xml  Dear Helen Ryan: I am writing to answer the qu...   \n",
       "3      doc1826.xml  Dear Sir, I'm writing to you to complain about...   \n",
       "4      doc1198.xml  Dear Sir or Madam, I am writing to complain ab...   \n",
       "...            ...                                                ...   \n",
       "1239   doc2311.xml  June 17th, 2000 Dear Sir, I am writing this le...   \n",
       "1240   doc2305.xml  Dear Mr Robertson, Thank you for effort which ...   \n",
       "1241   doc2463.xml  To the manger of the Circle Theatre Mr Smith C...   \n",
       "1242    doc365.xml  Dear Mr Brown, I went to the Circle Theatre ye...   \n",
       "1243    doc403.xml  13.06.2000 Dear Mrs. Ryan, you very much for y...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "0     [., is, make, The, attempt, invite, holidy, , ...                  20   \n",
       "1     [stayed in, holidays, show, was, see, diferent...                  15   \n",
       "2     [to, an other, august, rather, log cabins, its...                  12   \n",
       "3     [None, deceiveful, it, into, character, of, ad...                  25   \n",
       "4     [musical, which, it, didn't make us happy, Non...                  33   \n",
       "...                                                 ...                 ...   \n",
       "1239  [whom, am I, starring, of, will, started, enit...                  10   \n",
       "1240  [your, ,, three days, programm, advertisment, ...                  10   \n",
       "1241  [a, trip, free-time, for, different, informati...                  18   \n",
       "1242  [got, only, sign, What, quite not, it, no, dif...                  17   \n",
       "1243  [thank, have had, None, According to, Accomoda...                  16   \n",
       "\n",
       "                                            Corrections  \\\n",
       "0     [,, ,, makes, For the, a, take you up on, invi...   \n",
       "1     [went to, a, holiday, were, seeing, different,...   \n",
       "2     [another, August, a, log cabin, it's, options,...   \n",
       "3     [deceitful, disappointing, actor, advertising,...   \n",
       "4     [the, of, what, went wrong, theater, theatre, ...   \n",
       "...                                                 ...   \n",
       "1239  [how, I am, ,, acting, for, would, start, it, ...   \n",
       "1240  [the, three-day, programme, ,, concerning, adv...   \n",
       "1241  [free time, information, ,, ,, tourists, parts...   \n",
       "1242  [was, That, not quite, one, ,, No, contrary, t...   \n",
       "1243  [Thank, had, according to, because of, Accommo...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "0     [RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...          2.3  \n",
       "1     [RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...          3.2  \n",
       "2     [UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]          4.3  \n",
       "3     [RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...          4.3  \n",
       "4     [UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...          3.2  \n",
       "...                                                 ...          ...  \n",
       "1239  [R, W, MP, RV, RT, TV, FV, MA, MD, DV, RJ, S, RV]          3.1  \n",
       "1240  [RD, UP, DJ, S, MP, MT, S, MD, MP, S, RJ, UY, ...          4.3  \n",
       "1241  [UD, UN, UP, UT, UJ, CN, MP, MP, UD, AGN, AGN,...         2.3T  \n",
       "1242  [RV, UY, UN, RA, W, RA, MP, RP, RY, RT, UN, RA...          4.2  \n",
       "1243  [RP, TV, R, RP, S, MD, AGN, RP, SX, R, RY, RP,...          5.1  \n",
       "\n",
       "[1244 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we generate a list to create a dataframe\n",
    "\n",
    "dataframe_list = []  # start with empty list\n",
    "for xml_file in list_of_xml_files:\n",
    "    dataframe_list.append(parse_xml(\n",
    "        \"{}\".format(xml_file), 1))  # parse_xml() is a function created in a\n",
    "    # separate notebook, it takes an xml file from the FCE dataset and grabs\n",
    "    # a student's answer data for one question, note the number as the second argument\n",
    "\n",
    "fce_df_answer_1 = pd.DataFrame(dataframe_list)\n",
    "column_headers = [\n",
    "    \"Document_Name\", \"Response\", \"Mistakes\", \"Number_of_Mistakes\",\n",
    "    \"Corrections\", \"Correction_Codes\", \"Answer_Score\"\n",
    "]\n",
    "fce_df_answer_1.columns = column_headers\n",
    "\n",
    "# check it out\n",
    "print(\"fce_df_answer_1\")\n",
    "fce_df_answer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.784800Z",
     "start_time": "2021-08-23T01:59:22.155903Z"
    },
    "cell_style": "split",
    "hidden": true,
    "hide_input": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fce_df_answer_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc2485.xml</td>\n",
       "      <td>Shopping is part of our life. I don't like sho...</td>\n",
       "      <td>[imagene, friday, ., of the, pay, friday, to, ...</td>\n",
       "      <td>32</td>\n",
       "      <td>[imagine, Friday, ?, paid, Friday, in, queues,...</td>\n",
       "      <td>[RV, S, RP, RP, U, TV, RP, UT, RT, UD, FN, AS,...</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1832.xml</td>\n",
       "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
       "      <td>[in, cost, bath, whether, out, taking a sunbat...</td>\n",
       "      <td>15</td>\n",
       "      <td>[on, coast, swim, weather, sunbathing, As, go,...</td>\n",
       "      <td>[RT, RN, RN, SX, UY, DV, RT, RV, SX, L, RT, RV...</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc426.xml</td>\n",
       "      <td>Dear Kim: How are you? I'm fine. I finish scho...</td>\n",
       "      <td>[it, He's, handsom, lights of the stage, becau...</td>\n",
       "      <td>11</td>\n",
       "      <td>[It, he's, handsome, stage lights, and, had, l...</td>\n",
       "      <td>[RP, RP, S, W, RC, TV, RV, R, MY, MP, RT, DD]</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1826.xml</td>\n",
       "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
       "      <td>[extremly, pacefully, run, explain, harder, he...</td>\n",
       "      <td>23</td>\n",
       "      <td>[extremely, peacefully, ,, ran, tell, hard, hi...</td>\n",
       "      <td>[DY, S, MP, TV, RV, FY, RD, RV, RD, RN, FV, RV...</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1198.xml</td>\n",
       "      <td>People who in the city use lots of technologic...</td>\n",
       "      <td>[,, lives, ,, life style, easy, more fast, the...</td>\n",
       "      <td>41</td>\n",
       "      <td>[live, lifestyle, easier, and, faster, twenty-...</td>\n",
       "      <td>[UP, AGV, UP, RP, FJ, MC, IJ, R, UD, MP, MP, U...</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>doc2311.xml</td>\n",
       "      <td>Modern technology been changing human life sin...</td>\n",
       "      <td>[have, the, many, eletricity, than, t.v., , wh...</td>\n",
       "      <td>14</td>\n",
       "      <td>[has, man, electricity, then, TV, . When, mill...</td>\n",
       "      <td>[AGV, UD, R, S, SX, RP, RP, S, RP, MP, UD, RV,...</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>doc2305.xml</td>\n",
       "      <td>The Home of the Future Dear Reader, I have dec...</td>\n",
       "      <td>[obey, ,, every thing, furiture, programm, jus...</td>\n",
       "      <td>13</td>\n",
       "      <td>[our, respond, everything, furniture, programm...</td>\n",
       "      <td>[MD, RV, UP, RP, S, S, W, RT, MD, MV, RN, CL, ...</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>doc2463.xml</td>\n",
       "      <td>How modern technology changed your daily life!...</td>\n",
       "      <td>[place, since, TV, None, washing-machine, avai...</td>\n",
       "      <td>20</td>\n",
       "      <td>[importance, in, beginning of, ,, TVs, washing...</td>\n",
       "      <td>[RN, RT, MN, MP, FN, FN, UP, FJ, MP, S, MN, MP...</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>doc365.xml</td>\n",
       "      <td>How has modern technology changed your daily l...</td>\n",
       "      <td>[had a gigantic improvement, all became, invol...</td>\n",
       "      <td>17</td>\n",
       "      <td>[has improved gigantically, have all become, i...</td>\n",
       "      <td>[AS, TV, AGV, MD, RD, RA, S, UD, AGV, FN, AGA,...</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>doc403.xml</td>\n",
       "      <td>\"Shopping is not always enjoyable\". Before we ...</td>\n",
       "      <td>[statemant, about, stands for, luxuary, contes...</td>\n",
       "      <td>22</td>\n",
       "      <td>[statement, means, luxury, context, on, what y...</td>\n",
       "      <td>[S, UT, RV, S, RN, RT, UT, W, R, S, MQ, RT, RN...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1244 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "0      doc2485.xml  Shopping is part of our life. I don't like sho...   \n",
       "1      doc1832.xml  Unfortunately, Pat wasn't very good at keeping...   \n",
       "2       doc426.xml  Dear Kim: How are you? I'm fine. I finish scho...   \n",
       "3      doc1826.xml  Unfortunately, Pat wasn't very good at keeping...   \n",
       "4      doc1198.xml  People who in the city use lots of technologic...   \n",
       "...            ...                                                ...   \n",
       "1239   doc2311.xml  Modern technology been changing human life sin...   \n",
       "1240   doc2305.xml  The Home of the Future Dear Reader, I have dec...   \n",
       "1241   doc2463.xml  How modern technology changed your daily life!...   \n",
       "1242    doc365.xml  How has modern technology changed your daily l...   \n",
       "1243    doc403.xml  \"Shopping is not always enjoyable\". Before we ...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "0     [imagene, friday, ., of the, pay, friday, to, ...                  32   \n",
       "1     [in, cost, bath, whether, out, taking a sunbat...                  15   \n",
       "2     [it, He's, handsom, lights of the stage, becau...                  11   \n",
       "3     [extremly, pacefully, run, explain, harder, he...                  23   \n",
       "4     [,, lives, ,, life style, easy, more fast, the...                  41   \n",
       "...                                                 ...                 ...   \n",
       "1239  [have, the, many, eletricity, than, t.v., , wh...                  14   \n",
       "1240  [obey, ,, every thing, furiture, programm, jus...                  13   \n",
       "1241  [place, since, TV, None, washing-machine, avai...                  20   \n",
       "1242  [had a gigantic improvement, all became, invol...                  17   \n",
       "1243  [statemant, about, stands for, luxuary, contes...                  22   \n",
       "\n",
       "                                            Corrections  \\\n",
       "0     [imagine, Friday, ?, paid, Friday, in, queues,...   \n",
       "1     [on, coast, swim, weather, sunbathing, As, go,...   \n",
       "2     [It, he's, handsome, stage lights, and, had, l...   \n",
       "3     [extremely, peacefully, ,, ran, tell, hard, hi...   \n",
       "4     [live, lifestyle, easier, and, faster, twenty-...   \n",
       "...                                                 ...   \n",
       "1239  [has, man, electricity, then, TV, . When, mill...   \n",
       "1240  [our, respond, everything, furniture, programm...   \n",
       "1241  [importance, in, beginning of, ,, TVs, washing...   \n",
       "1242  [has improved gigantically, have all become, i...   \n",
       "1243  [statement, means, luxury, context, on, what y...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "0     [RV, S, RP, RP, U, TV, RP, UT, RT, UD, FN, AS,...          2.2  \n",
       "1     [RT, RN, RN, SX, UY, DV, RT, RV, SX, L, RT, RV...          3.1  \n",
       "2         [RP, RP, S, W, RC, TV, RV, R, MY, MP, RT, DD]          4.3  \n",
       "3     [DY, S, MP, TV, RV, FY, RD, RV, RD, RN, FV, RV...          5.1  \n",
       "4     [UP, AGV, UP, RP, FJ, MC, IJ, R, UD, MP, MP, U...          3.2  \n",
       "...                                                 ...          ...  \n",
       "1239  [AGV, UD, R, S, SX, RP, RP, S, RP, MP, UD, RV,...          3.2  \n",
       "1240  [MD, RV, UP, RP, S, S, W, RT, MD, MV, RN, CL, ...          5.1  \n",
       "1241  [RN, RT, MN, MP, FN, FN, UP, FJ, MP, S, MN, MP...          3.3  \n",
       "1242  [AS, TV, AGV, MD, RD, RA, S, UD, AGV, FN, AGA,...          3.3  \n",
       "1243  [S, UT, RV, S, RN, RT, UT, W, R, S, MQ, RT, RN...          4.2  \n",
       "\n",
       "[1244 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now for the 2nd answer\n",
    "\n",
    "dataframe_list = []  # start with empty list\n",
    "for xml_file in list_of_xml_files:\n",
    "    dataframe_list.append(parse_xml(\"{}\".format(xml_file),\n",
    "                                    2))  # here it is! answer 2!\n",
    "\n",
    "fce_df_answer_2 = pd.DataFrame(dataframe_list)\n",
    "column_headers = [\n",
    "    \"Document_Name\", \"Response\", \"Mistakes\", \"Number_of_Mistakes\",\n",
    "    \"Corrections\", \"Correction_Codes\", \"Answer_Score\"\n",
    "]\n",
    "fce_df_answer_2.columns = column_headers\n",
    "\n",
    "# check it out\n",
    "print(\"fce_df_answer_2\")\n",
    "fce_df_answer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The two DataFrames are merged into one below, totaling 2,488 answers from 1,244 students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.838841Z",
     "start_time": "2021-08-23T01:59:22.788607Z"
    },
    "cell_style": "center",
    "hidden": true,
    "hide_input": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fce_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc2485.xml</td>\n",
       "      <td>Dear Helen I have received your letter which m...</td>\n",
       "      <td>[., is, make, The, attempt, invite, holidy, , ...</td>\n",
       "      <td>20</td>\n",
       "      <td>[,, ,, makes, For the, a, take you up on, invi...</td>\n",
       "      <td>[RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1832.xml</td>\n",
       "      <td>Dear Sir, Last week I London for . During my s...</td>\n",
       "      <td>[stayed in, holidays, show, was, see, diferent...</td>\n",
       "      <td>15</td>\n",
       "      <td>[went to, a, holiday, were, seeing, different,...</td>\n",
       "      <td>[RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc426.xml</td>\n",
       "      <td>Dear Helen Ryan: I am writing to answer the qu...</td>\n",
       "      <td>[to, an other, august, rather, log cabins, its...</td>\n",
       "      <td>12</td>\n",
       "      <td>[another, August, a, log cabin, it's, options,...</td>\n",
       "      <td>[UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1826.xml</td>\n",
       "      <td>Dear Sir, I'm writing to you to complain about...</td>\n",
       "      <td>[None, deceiveful, it, into, character, of, ad...</td>\n",
       "      <td>25</td>\n",
       "      <td>[deceitful, disappointing, actor, advertising,...</td>\n",
       "      <td>[RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1198.xml</td>\n",
       "      <td>Dear Sir or Madam, I am writing to complain ab...</td>\n",
       "      <td>[musical, which, it, didn't make us happy, Non...</td>\n",
       "      <td>33</td>\n",
       "      <td>[the, of, what, went wrong, theater, theatre, ...</td>\n",
       "      <td>[UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>doc2311.xml</td>\n",
       "      <td>Modern technology been changing human life sin...</td>\n",
       "      <td>[have, the, many, eletricity, than, t.v., , wh...</td>\n",
       "      <td>14</td>\n",
       "      <td>[has, man, electricity, then, TV, . When, mill...</td>\n",
       "      <td>[AGV, UD, R, S, SX, RP, RP, S, RP, MP, UD, RV,...</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>doc2305.xml</td>\n",
       "      <td>The Home of the Future Dear Reader, I have dec...</td>\n",
       "      <td>[obey, ,, every thing, furiture, programm, jus...</td>\n",
       "      <td>13</td>\n",
       "      <td>[our, respond, everything, furniture, programm...</td>\n",
       "      <td>[MD, RV, UP, RP, S, S, W, RT, MD, MV, RN, CL, ...</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>doc2463.xml</td>\n",
       "      <td>How modern technology changed your daily life!...</td>\n",
       "      <td>[place, since, TV, None, washing-machine, avai...</td>\n",
       "      <td>20</td>\n",
       "      <td>[importance, in, beginning of, ,, TVs, washing...</td>\n",
       "      <td>[RN, RT, MN, MP, FN, FN, UP, FJ, MP, S, MN, MP...</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>doc365.xml</td>\n",
       "      <td>How has modern technology changed your daily l...</td>\n",
       "      <td>[had a gigantic improvement, all became, invol...</td>\n",
       "      <td>17</td>\n",
       "      <td>[has improved gigantically, have all become, i...</td>\n",
       "      <td>[AS, TV, AGV, MD, RD, RA, S, UD, AGV, FN, AGA,...</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>doc403.xml</td>\n",
       "      <td>\"Shopping is not always enjoyable\". Before we ...</td>\n",
       "      <td>[statemant, about, stands for, luxuary, contes...</td>\n",
       "      <td>22</td>\n",
       "      <td>[statement, means, luxury, context, on, what y...</td>\n",
       "      <td>[S, UT, RV, S, RN, RT, UT, W, R, S, MQ, RT, RN...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2488 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "0      doc2485.xml  Dear Helen I have received your letter which m...   \n",
       "1      doc1832.xml  Dear Sir, Last week I London for . During my s...   \n",
       "2       doc426.xml  Dear Helen Ryan: I am writing to answer the qu...   \n",
       "3      doc1826.xml  Dear Sir, I'm writing to you to complain about...   \n",
       "4      doc1198.xml  Dear Sir or Madam, I am writing to complain ab...   \n",
       "...            ...                                                ...   \n",
       "2483   doc2311.xml  Modern technology been changing human life sin...   \n",
       "2484   doc2305.xml  The Home of the Future Dear Reader, I have dec...   \n",
       "2485   doc2463.xml  How modern technology changed your daily life!...   \n",
       "2486    doc365.xml  How has modern technology changed your daily l...   \n",
       "2487    doc403.xml  \"Shopping is not always enjoyable\". Before we ...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "0     [., is, make, The, attempt, invite, holidy, , ...                  20   \n",
       "1     [stayed in, holidays, show, was, see, diferent...                  15   \n",
       "2     [to, an other, august, rather, log cabins, its...                  12   \n",
       "3     [None, deceiveful, it, into, character, of, ad...                  25   \n",
       "4     [musical, which, it, didn't make us happy, Non...                  33   \n",
       "...                                                 ...                 ...   \n",
       "2483  [have, the, many, eletricity, than, t.v., , wh...                  14   \n",
       "2484  [obey, ,, every thing, furiture, programm, jus...                  13   \n",
       "2485  [place, since, TV, None, washing-machine, avai...                  20   \n",
       "2486  [had a gigantic improvement, all became, invol...                  17   \n",
       "2487  [statemant, about, stands for, luxuary, contes...                  22   \n",
       "\n",
       "                                            Corrections  \\\n",
       "0     [,, ,, makes, For the, a, take you up on, invi...   \n",
       "1     [went to, a, holiday, were, seeing, different,...   \n",
       "2     [another, August, a, log cabin, it's, options,...   \n",
       "3     [deceitful, disappointing, actor, advertising,...   \n",
       "4     [the, of, what, went wrong, theater, theatre, ...   \n",
       "...                                                 ...   \n",
       "2483  [has, man, electricity, then, TV, . When, mill...   \n",
       "2484  [our, respond, everything, furniture, programm...   \n",
       "2485  [importance, in, beginning of, ,, TVs, washing...   \n",
       "2486  [has improved gigantically, have all become, i...   \n",
       "2487  [statement, means, luxury, context, on, what y...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "0     [RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...          2.3  \n",
       "1     [RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...          3.2  \n",
       "2     [UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]          4.3  \n",
       "3     [RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...          4.3  \n",
       "4     [UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...          3.2  \n",
       "...                                                 ...          ...  \n",
       "2483  [AGV, UD, R, S, SX, RP, RP, S, RP, MP, UD, RV,...          3.2  \n",
       "2484  [MD, RV, UP, RP, S, S, W, RT, MD, MV, RN, CL, ...          5.1  \n",
       "2485  [RN, RT, MN, MP, FN, FN, UP, FJ, MP, S, MN, MP...          3.3  \n",
       "2486  [AS, TV, AGV, MD, RD, RA, S, UD, AGV, FN, AGA,...          3.3  \n",
       "2487  [S, UT, RV, S, RN, RT, UT, W, R, S, MQ, RT, RN...          4.2  \n",
       "\n",
       "[2488 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append the two dataframes together\n",
    "\n",
    "fce_df = fce_df_answer_1.append(fce_df_answer_2).reset_index(drop=True)\n",
    "print(\"fce_df\")\n",
    "fce_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "An overview of the text/numerical cleaning and spacy-features engineered from the answer text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Initial Cleaning\n",
    "\n",
    "An overview of the starting variables are below. None of them quite need cleaning yet due to the nature of this project, but the score that the student responses received does have some issues.\n",
    "* Student response\n",
    "    * Consists only of words and punctuation used correctly by the student\n",
    "    * Cleaning not needed\n",
    "* Mistakes\n",
    "    * List of the words and punctuation used incorrectly\n",
    "    * Used to derive the next variable\n",
    "    * Cleaning not needed\n",
    "* Number of mistakes\n",
    "    * A simple count\n",
    "    * Cleaning not needed\n",
    "* Corrections\n",
    "    * List of words and punctuation that would replace the mistakes\n",
    "    * Cleaning not needed (not going to separate)\n",
    "* Correction codes\n",
    "    * List of the codes that represent the grammatical mistakes\n",
    "        * Assigned by the graders of the student responses\n",
    "    * Cleaning done after separating later\n",
    "* Answer score\n",
    "    * There seems to be some values that are not numerical\n",
    "    * Explored and addressed in this section\n",
    "\n",
    "**Note:** Treatment of outliers in numerical variables is considered later, after the original spacy features are derived from the student responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Checking out the Answer Scores\n",
    "\n",
    "* Characters that are not numerical or raise a question\n",
    "* For each of these characters I go back to the .xml file and look into why it could be \"weird\"\n",
    "* Unfortunately, the research I got the .xml files from doesn't go in-depth as to explain what all of the answer scores mean, so I really only have the .xml files to go off of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.850199Z",
     "start_time": "2021-08-23T01:59:22.841736Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.3',\n",
       " '3.2',\n",
       " '4.3',\n",
       " '3.1',\n",
       " '3.3',\n",
       " '4.1',\n",
       " '2.3T',\n",
       " '4.2',\n",
       " '5.2',\n",
       " '5.1',\n",
       " '2.2',\n",
       " '5.3',\n",
       " '.2',\n",
       " '2.1',\n",
       " '1.3',\n",
       " 'S',\n",
       " '1.1',\n",
       " '1.2',\n",
       " 0,\n",
       " '0',\n",
       " '2.',\n",
       " '.1',\n",
       " '1',\n",
       " '5/1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fce_df.Answer_Score.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.862516Z",
     "start_time": "2021-08-23T01:59:22.852990Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3     341\n",
       "3.2     325\n",
       "3.1     295\n",
       "4.1     257\n",
       "4.2     209\n",
       "4.3     200\n",
       "5.1     184\n",
       "2.3     167\n",
       "2.3T    132\n",
       "2.2     107\n",
       "5.2      91\n",
       "5.3      52\n",
       "2.1      50\n",
       "1.3      32\n",
       "0        15\n",
       "1.2      13\n",
       "0         5\n",
       "S         4\n",
       "1.1       3\n",
       ".2        2\n",
       "1         1\n",
       "5/1       1\n",
       ".1        1\n",
       "2.        1\n",
       "Name: Answer_Score, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fce_df.Answer_Score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "As can be seen in the cells above, there exist several characters that are not numerical or raise questions. They're listed here and explored further in the rest of this section.\n",
    "\n",
    "* 2.3T\n",
    "* 0 and 0 (one is a string and one is an int)\n",
    "* S\n",
    "* .2\n",
    "* 5/1\n",
    "* .1\n",
    "* 2.\n",
    "* 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.880987Z",
     "start_time": "2021-08-23T01:59:22.868913Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a function that will create a subDataFrame\n",
    "def create_df(weird_value):\n",
    "    weird_value_df = fce_df[fce_df[\"Answer_Score\"] == \"{}\".format(weird_value)]\n",
    "    return weird_value_df   \n",
    "\n",
    "# drop rows with no answer scores\n",
    "no_scores_df = fce_df[fce_df.isna().any(axis=1)]\n",
    "\n",
    "fce_df = fce_df.drop(no_scores_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.3T\n",
    "\n",
    "* 132 total\n",
    "* Removed the \"T\" and treated as 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.929727Z",
     "start_time": "2021-08-23T01:59:22.886467Z"
    },
    "cell_style": "center",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>doc383.xml</td>\n",
       "      <td>Dear Sir or Madam, I'm to you to complain abou...</td>\n",
       "      <td>[writting, theatre, for me very disappointing,...</td>\n",
       "      <td>25</td>\n",
       "      <td>[writing, very disappointing for me, ., absenc...</td>\n",
       "      <td>[IV, UN, W, RP, DN, MT, FV, SX, RJ, CN, RT, UP...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>doc1775.xml</td>\n",
       "      <td>17.06.2000 Hello Sir, \" very that I have to wr...</td>\n",
       "      <td>[Um, unpleased, in, Theater, points, because, ...</td>\n",
       "      <td>20</td>\n",
       "      <td>[I'm, unhappy, at, Theatre, ,, reasons, why, a...</td>\n",
       "      <td>[S, RJ, RT, SA, MP, RN, R, UP, RV, AGD, SA, RN...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>doc553.xml</td>\n",
       "      <td>Dear Mr Robertson, On behalf of our class I wo...</td>\n",
       "      <td>[,, indeed, about, for, change, suitable, unti...</td>\n",
       "      <td>20</td>\n",
       "      <td>[in, for, the, the, on, chance, compatible, by...</td>\n",
       "      <td>[UP, MT, UY, RT, MD, MD, R, MT, UT, RN, RJ, RT...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>doc2296.xml</td>\n",
       "      <td>Dear I'm writing you about musical show that I...</td>\n",
       "      <td>[Mr/, in, complain, ,, None, have visited, wee...</td>\n",
       "      <td>13</td>\n",
       "      <td>[Sir/Madam, to, to complain, the, visited, wen...</td>\n",
       "      <td>[RN, S, MT, UT, FV, MD, UP, RV, TV, MP, R, FJ,...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>doc547.xml</td>\n",
       "      <td>12.12.2000 Dear Mr Robertson, I am writing to ...</td>\n",
       "      <td>[greatful, to go, its, in, on, is, make up, or...</td>\n",
       "      <td>15</td>\n",
       "      <td>[grateful, go, to, in, an, at, at, the, will b...</td>\n",
       "      <td>[S, FV, MT, MT, RD, RT, MT, UT, MD, TV, MD, MD...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>doc772.xml</td>\n",
       "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
       "      <td>[explain, chose, companions of class, and, alw...</td>\n",
       "      <td>21</td>\n",
       "      <td>[tell, chosen, classmates, was, was always, pr...</td>\n",
       "      <td>[RV, TV, DN, UC, W, AGV, IV, RV, R, IV, UD, UD...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>doc2049.xml</td>\n",
       "      <td>Last week I had planned to change my old baske...</td>\n",
       "      <td>[a , corect, outdoor, visited, during, . The, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[correct, the right, outdoors, in, looked arou...</td>\n",
       "      <td>[RJ, S, L, DY, MT, RV, MD, RT, RP, MP, RA, UA,...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>doc405.xml</td>\n",
       "      <td>How has modern technology changed your daily l...</td>\n",
       "      <td>[has, before, can, In, . The, human, we, be co...</td>\n",
       "      <td>20</td>\n",
       "      <td>[have, back, to, ago, could, As, , the, humans...</td>\n",
       "      <td>[AGV, MY, MT, RY, TV, R, RT, RP, FN, RA, RV, R...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>doc1234.xml</td>\n",
       "      <td>\"THE RIGHT PERSON\" MAY 29, 1997. IT WAS MY FIR...</td>\n",
       "      <td>[CLOUSE, VERY WELL THE AREA, IN, COURNER, HOUS...</td>\n",
       "      <td>32</td>\n",
       "      <td>[,, ,, NUMBER, CLOSE, THE AREA VERY WELL, THE,...</td>\n",
       "      <td>[MP, MP, MN, S, W, MD, RT, S, RN, RC, RN, RP, ...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>doc2701.xml</td>\n",
       "      <td>From the of the century to now, modern technol...</td>\n",
       "      <td>[begining, the, modernism, None, confortable, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>[beginning, modernisation, comfortable, more c...</td>\n",
       "      <td>[S, UD, RN, FJ, S, R, UD, AGN, RT, RQ, RP, UA,...</td>\n",
       "      <td>2.3T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "11      doc383.xml  Dear Sir or Madam, I'm to you to complain abou...   \n",
       "36     doc1775.xml  17.06.2000 Hello Sir, \" very that I have to wr...   \n",
       "44      doc553.xml  Dear Mr Robertson, On behalf of our class I wo...   \n",
       "47     doc2296.xml  Dear I'm writing you about musical show that I...   \n",
       "48      doc547.xml  12.12.2000 Dear Mr Robertson, I am writing to ...   \n",
       "...            ...                                                ...   \n",
       "2273    doc772.xml  Unfortunately, Pat wasn't very good at keeping...   \n",
       "2309   doc2049.xml  Last week I had planned to change my old baske...   \n",
       "2327    doc405.xml  How has modern technology changed your daily l...   \n",
       "2457   doc1234.xml  \"THE RIGHT PERSON\" MAY 29, 1997. IT WAS MY FIR...   \n",
       "2461   doc2701.xml  From the of the century to now, modern technol...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "11    [writting, theatre, for me very disappointing,...                  25   \n",
       "36    [Um, unpleased, in, Theater, points, because, ...                  20   \n",
       "44    [,, indeed, about, for, change, suitable, unti...                  20   \n",
       "47    [Mr/, in, complain, ,, None, have visited, wee...                  13   \n",
       "48    [greatful, to go, its, in, on, is, make up, or...                  15   \n",
       "...                                                 ...                 ...   \n",
       "2273  [explain, chose, companions of class, and, alw...                  21   \n",
       "2309  [a , corect, outdoor, visited, during, . The, ...                  15   \n",
       "2327  [has, before, can, In, . The, human, we, be co...                  20   \n",
       "2457  [CLOUSE, VERY WELL THE AREA, IN, COURNER, HOUS...                  32   \n",
       "2461  [begining, the, modernism, None, confortable, ...                  27   \n",
       "\n",
       "                                            Corrections  \\\n",
       "11    [writing, very disappointing for me, ., absenc...   \n",
       "36    [I'm, unhappy, at, Theatre, ,, reasons, why, a...   \n",
       "44    [in, for, the, the, on, chance, compatible, by...   \n",
       "47    [Sir/Madam, to, to complain, the, visited, wen...   \n",
       "48    [grateful, go, to, in, an, at, at, the, will b...   \n",
       "...                                                 ...   \n",
       "2273  [tell, chosen, classmates, was, was always, pr...   \n",
       "2309  [correct, the right, outdoors, in, looked arou...   \n",
       "2327  [have, back, to, ago, could, As, , the, humans...   \n",
       "2457  [,, ,, NUMBER, CLOSE, THE AREA VERY WELL, THE,...   \n",
       "2461  [beginning, modernisation, comfortable, more c...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "11    [IV, UN, W, RP, DN, MT, FV, SX, RJ, CN, RT, UP...         2.3T  \n",
       "36    [S, RJ, RT, SA, MP, RN, R, UP, RV, AGD, SA, RN...         2.3T  \n",
       "44    [UP, MT, UY, RT, MD, MD, R, MT, UT, RN, RJ, RT...         2.3T  \n",
       "47    [RN, S, MT, UT, FV, MD, UP, RV, TV, MP, R, FJ,...         2.3T  \n",
       "48    [S, FV, MT, MT, RD, RT, MT, UT, MD, TV, MD, MD...         2.3T  \n",
       "...                                                 ...          ...  \n",
       "2273  [RV, TV, DN, UC, W, AGV, IV, RV, R, IV, UD, UD...         2.3T  \n",
       "2309  [RJ, S, L, DY, MT, RV, MD, RT, RP, MP, RA, UA,...         2.3T  \n",
       "2327  [AGV, MY, MT, RY, TV, R, RT, RP, FN, RA, RV, R...         2.3T  \n",
       "2457  [MP, MP, MN, S, W, MD, RT, S, RN, RC, RN, RP, ...         2.3T  \n",
       "2461  [S, UD, RN, FJ, S, R, UD, AGN, RT, RQ, RP, UA,...         2.3T  \n",
       "\n",
       "[132 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_point_three_T_df = create_df(\"2.3T\")\n",
    "\n",
    "two_point_three_T_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.940849Z",
     "start_time": "2021-08-23T01:59:22.933080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# replace the T values with a blank\n",
    "fce_df[\"Answer_Score\"] = fce_df[\"Answer_Score\"].str.replace(\"T\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 0\n",
    "\n",
    "* Two 0-values\n",
    "    * 20 total records\n",
    "    * One is a string and the other an int\n",
    "* String 0\n",
    "    * May actually represent a score of zero\n",
    "    * There are only five of them\n",
    "    * Removed\n",
    "* Int 0\n",
    "    * Answer scores are missing from their .xml files\n",
    "    * Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.949492Z",
     "start_time": "2021-08-23T01:59:22.943616Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create the DataFrames of records that have these values\n",
    "string_zero_df = create_df(\"0\")\n",
    "int_zero_df = fce_df[fce_df[\"Answer_Score\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.979092Z",
     "start_time": "2021-08-23T01:59:22.952333Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>doc1586.xml</td>\n",
       "      <td>Dear Mr Robertson you. I need some . Because m...</td>\n",
       "      <td>[I'm sorry about writing, the, Letter, None, F...</td>\n",
       "      <td>59</td>\n",
       "      <td>[I'm sorry to have to write, this, letter, for...</td>\n",
       "      <td>[ID, RD, RP, RT, RP, W, MD, UT, M, RT, MC, AGN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>doc541.xml</td>\n",
       "      <td>Basle, 12th 2000 Dar Oxana, Thanks for your le...</td>\n",
       "      <td>[Decembre, wheter, it, social life, politic, i...</td>\n",
       "      <td>14</td>\n",
       "      <td>[December, whether, the, them, the, society, p...</td>\n",
       "      <td>[S, S, MD, AGA, RY, MD, RN, RJ, RT, RV, RV, SX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>doc2394.xml</td>\n",
       "      <td>Best Detective Stories of Agatha Christie - A...</td>\n",
       "      <td>[always was, or, caracthers, or, decieving, wo...</td>\n",
       "      <td>17</td>\n",
       "      <td>[The, has always been, and, characters, and, d...</td>\n",
       "      <td>[MD, TV, RC, S, RC, R, S, AGN, ID, RV, S, R, S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>doc444.xml</td>\n",
       "      <td>Dear Kim: I am sorry, I haven't written you bu...</td>\n",
       "      <td>[soon, for, the, on, ,,  \"of, wheel, None, rep...</td>\n",
       "      <td>20</td>\n",
       "      <td>[to, sooner, am, about, ,, ,, in, ., , \"Of, re...</td>\n",
       "      <td>[MT, FY, MV, RT, UD, MP, MP, RT, RP, RP, UN, F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>doc1586.xml</td>\n",
       "      <td>In my college It was dangerous, but I knew I h...</td>\n",
       "      <td>[tall, someting, got, None, buillding, got, al...</td>\n",
       "      <td>15</td>\n",
       "      <td>[tell, something, have got, building, building...</td>\n",
       "      <td>[R, SX, S, CE, CE, RV, AGN, S, RV, RP, AGN, AG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "1143   doc1586.xml  Dear Mr Robertson you. I need some . Because m...   \n",
       "1440    doc541.xml  Basle, 12th 2000 Dar Oxana, Thanks for your le...   \n",
       "1553   doc2394.xml   Best Detective Stories of Agatha Christie - A...   \n",
       "1629    doc444.xml  Dear Kim: I am sorry, I haven't written you bu...   \n",
       "2387   doc1586.xml  In my college It was dangerous, but I knew I h...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "1143  [I'm sorry about writing, the, Letter, None, F...                  59   \n",
       "1440  [Decembre, wheter, it, social life, politic, i...                  14   \n",
       "1553  [always was, or, caracthers, or, decieving, wo...                  17   \n",
       "1629  [soon, for, the, on, ,,  \"of, wheel, None, rep...                  20   \n",
       "2387  [tall, someting, got, None, buillding, got, al...                  15   \n",
       "\n",
       "                                            Corrections  \\\n",
       "1143  [I'm sorry to have to write, this, letter, for...   \n",
       "1440  [December, whether, the, them, the, society, p...   \n",
       "1553  [The, has always been, and, characters, and, d...   \n",
       "1629  [to, sooner, am, about, ,, ,, in, ., , \"Of, re...   \n",
       "2387  [tell, something, have got, building, building...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "1143  [ID, RD, RP, RT, RP, W, MD, UT, M, RT, MC, AGN...            0  \n",
       "1440  [S, S, MD, AGA, RY, MD, RN, RJ, RT, RV, RV, SX...            0  \n",
       "1553  [MD, TV, RC, S, RC, R, S, AGN, ID, RV, S, R, S...            0  \n",
       "1629  [MT, FY, MV, RT, UD, MP, MP, RT, RP, RP, UN, F...            0  \n",
       "2387  [R, SX, S, CE, CE, RV, AGN, S, RV, RP, AGN, AG...            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_zero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.991920Z",
     "start_time": "2021-08-23T01:59:22.983279Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Document_Name, Response, Mistakes, Number_of_Mistakes, Corrections, Correction_Codes, Answer_Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_zero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:22.999914Z",
     "start_time": "2021-08-23T01:59:22.995500Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zero_df = string_zero_df.append(int_zero_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.023349Z",
     "start_time": "2021-08-23T01:59:23.002518Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>doc1586.xml</td>\n",
       "      <td>Dear Mr Robertson you. I need some . Because m...</td>\n",
       "      <td>[I'm sorry about writing, the, Letter, None, F...</td>\n",
       "      <td>59</td>\n",
       "      <td>[I'm sorry to have to write, this, letter, for...</td>\n",
       "      <td>[ID, RD, RP, RT, RP, W, MD, UT, M, RT, MC, AGN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>doc541.xml</td>\n",
       "      <td>Basle, 12th 2000 Dar Oxana, Thanks for your le...</td>\n",
       "      <td>[Decembre, wheter, it, social life, politic, i...</td>\n",
       "      <td>14</td>\n",
       "      <td>[December, whether, the, them, the, society, p...</td>\n",
       "      <td>[S, S, MD, AGA, RY, MD, RN, RJ, RT, RV, RV, SX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>doc2394.xml</td>\n",
       "      <td>Best Detective Stories of Agatha Christie - A...</td>\n",
       "      <td>[always was, or, caracthers, or, decieving, wo...</td>\n",
       "      <td>17</td>\n",
       "      <td>[The, has always been, and, characters, and, d...</td>\n",
       "      <td>[MD, TV, RC, S, RC, R, S, AGN, ID, RV, S, R, S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>doc444.xml</td>\n",
       "      <td>Dear Kim: I am sorry, I haven't written you bu...</td>\n",
       "      <td>[soon, for, the, on, ,,  \"of, wheel, None, rep...</td>\n",
       "      <td>20</td>\n",
       "      <td>[to, sooner, am, about, ,, ,, in, ., , \"Of, re...</td>\n",
       "      <td>[MT, FY, MV, RT, UD, MP, MP, RT, RP, RP, UN, F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>doc1586.xml</td>\n",
       "      <td>In my college It was dangerous, but I knew I h...</td>\n",
       "      <td>[tall, someting, got, None, buillding, got, al...</td>\n",
       "      <td>15</td>\n",
       "      <td>[tell, something, have got, building, building...</td>\n",
       "      <td>[R, SX, S, CE, CE, RV, AGN, S, RV, RP, AGN, AG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "1143   doc1586.xml  Dear Mr Robertson you. I need some . Because m...   \n",
       "1440    doc541.xml  Basle, 12th 2000 Dar Oxana, Thanks for your le...   \n",
       "1553   doc2394.xml   Best Detective Stories of Agatha Christie - A...   \n",
       "1629    doc444.xml  Dear Kim: I am sorry, I haven't written you bu...   \n",
       "2387   doc1586.xml  In my college It was dangerous, but I knew I h...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "1143  [I'm sorry about writing, the, Letter, None, F...                  59   \n",
       "1440  [Decembre, wheter, it, social life, politic, i...                  14   \n",
       "1553  [always was, or, caracthers, or, decieving, wo...                  17   \n",
       "1629  [soon, for, the, on, ,,  \"of, wheel, None, rep...                  20   \n",
       "2387  [tall, someting, got, None, buillding, got, al...                  15   \n",
       "\n",
       "                                            Corrections  \\\n",
       "1143  [I'm sorry to have to write, this, letter, for...   \n",
       "1440  [December, whether, the, them, the, society, p...   \n",
       "1553  [The, has always been, and, characters, and, d...   \n",
       "1629  [to, sooner, am, about, ,, ,, in, ., , \"Of, re...   \n",
       "2387  [tell, something, have got, building, building...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "1143  [ID, RD, RP, RT, RP, W, MD, UT, M, RT, MC, AGN...            0  \n",
       "1440  [S, S, MD, AGA, RY, MD, RN, RJ, RT, RV, RV, SX...            0  \n",
       "1553  [MD, TV, RC, S, RC, R, S, AGN, ID, RV, S, R, S...            0  \n",
       "1629  [MT, FY, MV, RT, UD, MP, MP, RT, RP, RP, UN, F...            0  \n",
       "2387  [R, SX, S, CE, CE, RV, AGN, S, RV, RP, AGN, AG...            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.030803Z",
     "start_time": "2021-08-23T01:59:23.025727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(zero_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### S\n",
    "\n",
    "* 4 total\n",
    "* Answer score marked as 'S' in .xml files\n",
    "* Removed from dataset due to no existing key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.053830Z",
     "start_time": "2021-08-23T01:59:23.033471Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>doc1003.xml</td>\n",
       "      <td>Dear Mrs. Clark, Recently I was at the annual ...</td>\n",
       "      <td>[Jane, ,, a, possibility, ,, would be, much, e...</td>\n",
       "      <td>26</td>\n",
       "      <td>[the, opportunity, will be, many, really, the,...</td>\n",
       "      <td>[UN, UP, M, RD, RN, UP, TV, CQ, RY, MD, MC, W,...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>doc722.xml</td>\n",
       "      <td>Dear Miss Helen Ryan I was so to hear from you...</td>\n",
       "      <td>[None, suprise, on, win, it, you, to have, tri...</td>\n",
       "      <td>23</td>\n",
       "      <td>[surprise, surprised, in, have won, it, I, hav...</td>\n",
       "      <td>[DJ, S, RT, TV, UA, MA, RA, FV, UN, RT, MA, RN...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>doc2565.xml</td>\n",
       "      <td>Mrs. Jane Clark, I your advertisement about Ar...</td>\n",
       "      <td>[see, Internal, ., As, Advertisement, None, is...</td>\n",
       "      <td>28</td>\n",
       "      <td>[saw, the, International, as, The, advertiseme...</td>\n",
       "      <td>[TV, MD, RJ, UP, RP, MD, RP, RV, TV, AGN, UY, ...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>doc2302.xml</td>\n",
       "      <td>Dear Mr Robertson First of all I would like to...</td>\n",
       "      <td>[organised, None, Especially, suggest you some...</td>\n",
       "      <td>17</td>\n",
       "      <td>[have organised, In particular, The sightseein...</td>\n",
       "      <td>[TV, W, RY, MP, AS, RP, RP, MP, MP, RP, MT, MA...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "272    doc1003.xml  Dear Mrs. Clark, Recently I was at the annual ...   \n",
       "573     doc722.xml  Dear Miss Helen Ryan I was so to hear from you...   \n",
       "662    doc2565.xml  Mrs. Jane Clark, I your advertisement about Ar...   \n",
       "1015   doc2302.xml  Dear Mr Robertson First of all I would like to...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "272   [Jane, ,, a, possibility, ,, would be, much, e...                  26   \n",
       "573   [None, suprise, on, win, it, you, to have, tri...                  23   \n",
       "662   [see, Internal, ., As, Advertisement, None, is...                  28   \n",
       "1015  [organised, None, Especially, suggest you some...                  17   \n",
       "\n",
       "                                            Corrections  \\\n",
       "272   [the, opportunity, will be, many, really, the,...   \n",
       "573   [surprise, surprised, in, have won, it, I, hav...   \n",
       "662   [saw, the, International, as, The, advertiseme...   \n",
       "1015  [have organised, In particular, The sightseein...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "272   [UN, UP, M, RD, RN, UP, TV, CQ, RY, MD, MC, W,...            S  \n",
       "573   [DJ, S, RT, TV, UA, MA, RA, FV, UN, RT, MA, RN...            S  \n",
       "662   [TV, MD, RJ, UP, RP, MD, RP, RV, TV, AGN, UY, ...            S  \n",
       "1015  [TV, W, RY, MP, AS, RP, RP, MP, MP, RP, MT, MA...            S  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_df = create_df(\"S\")\n",
    "\n",
    "S_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.061134Z",
     "start_time": "2021-08-23T01:59:23.056509Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(S_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### .2\n",
    "\n",
    "* 2 total\n",
    "* Removed from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.080082Z",
     "start_time": "2021-08-23T01:59:23.063389Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>doc433.xml</td>\n",
       "      <td>Dear Sir or Madam, I am writing to complain ab...</td>\n",
       "      <td>[show, that, None, suppossed, imagen, complain...</td>\n",
       "      <td>17</td>\n",
       "      <td>[which, supposed, was supposed, imagine, compl...</td>\n",
       "      <td>[UN, RA, TV, S, S, DN, UN, RP, RP, SX, X, UN, ...</td>\n",
       "      <td>.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>doc2695.xml</td>\n",
       "      <td>Modern technology has changed my daily life, m...</td>\n",
       "      <td>[with, tv, program, just begins, doing, to, di...</td>\n",
       "      <td>22</td>\n",
       "      <td>[on, ,, ,, in, TV, programme, has just begun, ...</td>\n",
       "      <td>[MT, MN, MP, MP, RT, RP, SA, TV, MV, FV, MA, R...</td>\n",
       "      <td>.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "77      doc433.xml  Dear Sir or Madam, I am writing to complain ab...   \n",
       "1397   doc2695.xml  Modern technology has changed my daily life, m...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "77    [show, that, None, suppossed, imagen, complain...                  17   \n",
       "1397  [with, tv, program, just begins, doing, to, di...                  22   \n",
       "\n",
       "                                            Corrections  \\\n",
       "77    [which, supposed, was supposed, imagine, compl...   \n",
       "1397  [on, ,, ,, in, TV, programme, has just begun, ...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "77    [UN, RA, TV, S, S, DN, UN, RP, RP, SX, X, UN, ...           .2  \n",
       "1397  [MT, MN, MP, MP, RT, RP, SA, TV, MV, FV, MA, R...           .2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_two_df = create_df(\".2\")\n",
    "\n",
    "point_two_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.089478Z",
     "start_time": "2021-08-23T01:59:23.083529Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(point_two_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 5/1\n",
    "\n",
    "* Just 1\n",
    "* Removed from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.106435Z",
     "start_time": "2021-08-23T01:59:23.091820Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>doc1584.xml</td>\n",
       "      <td>Dear Kim: What a fantastic experience I had he...</td>\n",
       "      <td>[mantle, , sometimes, on, , that, sand, duo, ,...</td>\n",
       "      <td>11</td>\n",
       "      <td>[build, . Sometimes, into, . That, sang, a, du...</td>\n",
       "      <td>[DV, RP, RT, RP, SX, MD, RN, RP, UD, MD, UV, T...</td>\n",
       "      <td>5/1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "2416   doc1584.xml  Dear Kim: What a fantastic experience I had he...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "2416  [mantle, , sometimes, on, , that, sand, duo, ,...                  11   \n",
       "\n",
       "                                            Corrections  \\\n",
       "2416  [build, . Sometimes, into, . That, sang, a, du...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "2416  [DV, RP, RT, RP, SX, MD, RN, RP, UD, MD, UV, T...          5/1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_over_one_df = create_df(\"5/1\")\n",
    "\n",
    "five_over_one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.113331Z",
     "start_time": "2021-08-23T01:59:23.108698Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(five_over_one_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### .1\n",
    "\n",
    "* Just 1\n",
    "* Removed from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.136444Z",
     "start_time": "2021-08-23T01:59:23.123805Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>doc1558.xml</td>\n",
       "      <td>Dear Kim How are you? I am sorry that I didn't...</td>\n",
       "      <td>[letter, your, were, Quess, happened, have, li...</td>\n",
       "      <td>54</td>\n",
       "      <td>[letters, you, the, had been, Guess, was put o...</td>\n",
       "      <td>[AGN, DA, MD, TV, S, RV, TV, TV, TV, UP, AGA, ...</td>\n",
       "      <td>.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "1441   doc1558.xml  Dear Kim How are you? I am sorry that I didn't...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "1441  [letter, your, were, Quess, happened, have, li...                  54   \n",
       "\n",
       "                                            Corrections  \\\n",
       "1441  [letters, you, the, had been, Guess, was put o...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "1441  [AGN, DA, MD, TV, S, RV, TV, TV, TV, UP, AGA, ...           .1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_one_df = create_df(\".1\")\n",
    "\n",
    "point_one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.150025Z",
     "start_time": "2021-08-23T01:59:23.144013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(point_one_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### .2\n",
    "\n",
    "* Just 2\n",
    "* Removed from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.167526Z",
     "start_time": "2021-08-23T01:59:23.152615Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>doc433.xml</td>\n",
       "      <td>Dear Sir or Madam, I am writing to complain ab...</td>\n",
       "      <td>[show, that, None, suppossed, imagen, complain...</td>\n",
       "      <td>17</td>\n",
       "      <td>[which, supposed, was supposed, imagine, compl...</td>\n",
       "      <td>[UN, RA, TV, S, S, DN, UN, RP, RP, SX, X, UN, ...</td>\n",
       "      <td>.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>doc2695.xml</td>\n",
       "      <td>Modern technology has changed my daily life, m...</td>\n",
       "      <td>[with, tv, program, just begins, doing, to, di...</td>\n",
       "      <td>22</td>\n",
       "      <td>[on, ,, ,, in, TV, programme, has just begun, ...</td>\n",
       "      <td>[MT, MN, MP, MP, RT, RP, SA, TV, MV, FV, MA, R...</td>\n",
       "      <td>.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "77      doc433.xml  Dear Sir or Madam, I am writing to complain ab...   \n",
       "1397   doc2695.xml  Modern technology has changed my daily life, m...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "77    [show, that, None, suppossed, imagen, complain...                  17   \n",
       "1397  [with, tv, program, just begins, doing, to, di...                  22   \n",
       "\n",
       "                                            Corrections  \\\n",
       "77    [which, supposed, was supposed, imagine, compl...   \n",
       "1397  [on, ,, ,, in, TV, programme, has just begun, ...   \n",
       "\n",
       "                                       Correction_Codes Answer_Score  \n",
       "77    [UN, RA, TV, S, S, DN, UN, RP, RP, SX, X, UN, ...           .2  \n",
       "1397  [MT, MN, MP, MP, RT, RP, SA, TV, MV, FV, MA, R...           .2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_point_df = create_df(\"2.\")\n",
    "\n",
    "point_two_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.176988Z",
     "start_time": "2021-08-23T01:59:23.171143Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(point_two_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1\n",
    "\n",
    "* Just 1\n",
    "* Removed from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.196193Z",
     "start_time": "2021-08-23T01:59:23.180110Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>doc1638.xml</td>\n",
       "      <td>I do not agree that it is preferable to phone ...</td>\n",
       "      <td>[at, choose, belive, shop]</td>\n",
       "      <td>4</td>\n",
       "      <td>[choosing, believe, shops]</td>\n",
       "      <td>[UT, FV, S, FN, R]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "1466   doc1638.xml  I do not agree that it is preferable to phone ...   \n",
       "\n",
       "                        Mistakes  Number_of_Mistakes  \\\n",
       "1466  [at, choose, belive, shop]                   4   \n",
       "\n",
       "                     Corrections    Correction_Codes Answer_Score  \n",
       "1466  [choosing, believe, shops]  [UT, FV, S, FN, R]            1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_df = create_df(\"1\")\n",
    "\n",
    "one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.208332Z",
     "start_time": "2021-08-23T01:59:23.201776Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(one_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Playing Nice\n",
    "\n",
    "* Fixed some variable types\n",
    "* Dropping NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.215290Z",
     "start_time": "2021-08-23T01:59:23.210993Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df[\"Answer_Score\"] = fce_df.Answer_Score.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.225953Z",
     "start_time": "2021-08-23T01:59:23.218258Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_scores_df = fce_df[fce_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.234191Z",
     "start_time": "2021-08-23T01:59:23.228469Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df = fce_df.drop(no_scores_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Response Variable\n",
    "\n",
    "* Loaded with spacy first\n",
    "* Parsed the poems for spacy features\n",
    "    * Number of tokens (before removing stopwords)\n",
    "    * Stems (after stopword removal)\n",
    "    * Parts of speech for each token (before stopword removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.249468Z",
     "start_time": "2021-08-23T01:59:23.236713Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2457 entries, 0 to 2456\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Document_Name       2457 non-null   object \n",
      " 1   Response            2457 non-null   object \n",
      " 2   Mistakes            2457 non-null   object \n",
      " 3   Number_of_Mistakes  2457 non-null   int64  \n",
      " 4   Corrections         2457 non-null   object \n",
      " 5   Correction_Codes    2457 non-null   object \n",
      " 6   Answer_Score        2457 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 134.5+ KB\n"
     ]
    }
   ],
   "source": [
    "fce_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.540305Z",
     "start_time": "2021-08-23T01:59:23.252264Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get rid of punctuation manually since spacy misses these characters\n",
    "fce_df[\"Cleaned_Response\"] = fce_df[\"Response\"].str.replace(r'.', '')\n",
    "fce_df[\"Cleaned_Response\"] = fce_df[\"Cleaned_Response\"].str.replace(r',', '')\n",
    "fce_df[\"Cleaned_Response\"] = fce_df[\"Cleaned_Response\"].str.replace(r':', '')\n",
    "\n",
    "fce_df[\"Cleaned_Response\"] = fce_df[\"Cleaned_Response\"].replace('\\s+',\n",
    "                                                                  ' ',\n",
    "                                                                  regex=True)\n",
    "\n",
    "# make everything lowercase\n",
    "fce_df[\"Cleaned_Response\"] = fce_df[\"Cleaned_Response\"].str.lower()\n",
    "\n",
    "# couple more here\n",
    "patterns = [\n",
    "    '!', '\"', \"$\", \"%\", \"£\", \"&\", '  ', '   ', \"(\", \"=\", \"ô\", \"ö\", '0', '1',\n",
    "    '2', '3', '4', '5', '6', '7', '8', '9', '?', '-', '/', '`'\n",
    "]\n",
    "\n",
    "for pattern in patterns:\n",
    "    fce_df[\"Cleaned_Response\"] = fce_df[\"Cleaned_Response\"].str.replace(\n",
    "        r\"{}\".format(pattern), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T01:59:23.546657Z",
     "start_time": "2021-08-23T01:59:23.542138Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Ms Clark, Recently I visited an arts festival organized with your help. I enjoyed it very much and I think the idea of is great. However, I have some proposals its next year. , I stars and artists not from all the world, but from only six countries. This change will give opportunity to . proposition is about concerts. I that some concert halls are too small, so you should be sure about in advance. This year I noticed that there were only few plays and films. From my point of view, there should be more films because this part of the festival is interesting for people. And, , I should congratulate you the decision one weekend ticket for all events. I support this idea which is both for and . I hope you will consider my proposals. I am looking forward festival next year. Yours ,'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fce_df.Response.iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:24.806452Z",
     "start_time": "2021-08-23T01:59:23.549025Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# here we load the response variable in with spacy\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# create function to apply loading with spacy to a DataFrame column\n",
    "def load_with_spacy(column):\n",
    "    nlp_column = nlp(column)\n",
    "    return nlp_column\n",
    "\n",
    "# apply the function\n",
    "fce_df[\"NLP_Response\"] = fce_df.Cleaned_Response.apply(load_with_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:24.880593Z",
     "start_time": "2021-08-23T02:00:24.808042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split the cleaned response column into a list of words\n",
    "# so we can grab only the non-stopwords\n",
    "def split_into_list(text):\n",
    "    return text.split()\n",
    "\n",
    "fce_df[\"Cleaned_Response_List\"] = fce_df.Cleaned_Response.apply(split_into_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:24.888998Z",
     "start_time": "2021-08-23T02:00:24.882700Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dear helen i have received your letter which me happy first time in my life i have won competition i would like to your in july i only able to take my in july rest of the year i work i would prefer to stay in tent i think it is more enjoyable i don't know why but i have my childhood when i was kid i used to ask my mum to buy me a tent for my bedroom to sleep in there instead of bed i'm about tennis and swimming i used to take tennis and swimming when i was high school i have i go and tennis do i have to bring some cash me do you think would be more  i like to get some information about weather what it like in july over there sincerely\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fce_df.Cleaned_Response.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:24.896819Z",
     "start_time": "2021-08-23T02:00:24.892056Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make sure the response variable is a string\n",
    "\n",
    "fce_df[\"Response\"] = fce_df[\"Response\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:25.629448Z",
     "start_time": "2021-08-23T02:00:24.899587Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a feature from the cleaned variables without stopwords\n",
    "# to be parsed for lemmas/stems\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "fce_df[\"Cleaned_Response_No_Stop\"] = fce_df.Cleaned_Response_List.apply(\n",
    "    lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "In the following code block I create features with spacy from the response variable. Then, we take a look at the current state of our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:30.205450Z",
     "start_time": "2021-08-23T02:00:25.630984Z"
    },
    "hidden": true,
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "      <th>Cleaned_Response</th>\n",
       "      <th>NLP_Response</th>\n",
       "      <th>Cleaned_Response_List</th>\n",
       "      <th>Cleaned_Response_No_Stop</th>\n",
       "      <th>Number_of_Tokens</th>\n",
       "      <th>Joined_Cleaned_Response</th>\n",
       "      <th>PS_Stems</th>\n",
       "      <th>POS_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc2485.xml</td>\n",
       "      <td>Dear Helen I have received your letter which m...</td>\n",
       "      <td>[., is, make, The, attempt, invite, holidy, , ...</td>\n",
       "      <td>20</td>\n",
       "      <td>[,, ,, makes, For the, a, take you up on, invi...</td>\n",
       "      <td>[RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>dear helen i have received your letter which m...</td>\n",
       "      <td>(dear, helen, i, have, received, your, letter,...</td>\n",
       "      <td>[dear, helen, i, have, received, your, letter,...</td>\n",
       "      <td>[dear, helen, received, letter, happy, first, ...</td>\n",
       "      <td>143</td>\n",
       "      <td>dear helen received letter happy first time li...</td>\n",
       "      <td>[dear, helen, receiv, letter, happi, first, ti...</td>\n",
       "      <td>[ADJ, NOUN, PRON, AUX, VERB, PRON, NOUN, DET, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1832.xml</td>\n",
       "      <td>Dear Sir, Last week I London for . During my s...</td>\n",
       "      <td>[stayed in, holidays, show, was, see, diferent...</td>\n",
       "      <td>15</td>\n",
       "      <td>[went to, a, holiday, were, seeing, different,...</td>\n",
       "      <td>[RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>dear sir last week i london for during my stay...</td>\n",
       "      <td>(dear, sir, last, week, i, london, for, during...</td>\n",
       "      <td>[dear, sir, last, week, i, london, for, during...</td>\n",
       "      <td>[dear, sir, last, week, london, stay, beautifu...</td>\n",
       "      <td>197</td>\n",
       "      <td>dear sir last week london stay beautiful city ...</td>\n",
       "      <td>[dear, sir, last, week, london, stay, beauti, ...</td>\n",
       "      <td>[ADJ, NOUN, ADJ, NOUN, PRON, VERB, ADP, ADP, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc426.xml</td>\n",
       "      <td>Dear Helen Ryan: I am writing to answer the qu...</td>\n",
       "      <td>[to, an other, august, rather, log cabins, its...</td>\n",
       "      <td>12</td>\n",
       "      <td>[another, August, a, log cabin, it's, options,...</td>\n",
       "      <td>[UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]</td>\n",
       "      <td>4.3</td>\n",
       "      <td>dear helen ryan i am writing to answer the que...</td>\n",
       "      <td>(dear, helen, ryan, i, am, writing, to, answer...</td>\n",
       "      <td>[dear, helen, ryan, i, am, writing, to, answer...</td>\n",
       "      <td>[dear, helen, ryan, writing, answer, questions...</td>\n",
       "      <td>152</td>\n",
       "      <td>dear helen ryan writing answer questions asked...</td>\n",
       "      <td>[dear, helen, ryan, write, answer, question, a...</td>\n",
       "      <td>[ADJ, PROPN, NOUN, PRON, AUX, VERB, PART, VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1826.xml</td>\n",
       "      <td>Dear Sir, I'm writing to you to complain about...</td>\n",
       "      <td>[None, deceiveful, it, into, character, of, ad...</td>\n",
       "      <td>25</td>\n",
       "      <td>[deceitful, disappointing, actor, advertising,...</td>\n",
       "      <td>[RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>dear sir i'm writing to you to complain about ...</td>\n",
       "      <td>(dear, sir, i, 'm, writing, to, you, to, compl...</td>\n",
       "      <td>[dear, sir, i'm, writing, to, you, to, complai...</td>\n",
       "      <td>[dear, sir, i'm, writing, complain, experience...</td>\n",
       "      <td>198</td>\n",
       "      <td>dear sir i'm writing complain experience theat...</td>\n",
       "      <td>[dear, sir, i, 'm, write, complain, experi, th...</td>\n",
       "      <td>[ADJ, NOUN, PRON, AUX, VERB, ADP, PRON, PART, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1198.xml</td>\n",
       "      <td>Dear Sir or Madam, I am writing to complain ab...</td>\n",
       "      <td>[musical, which, it, didn't make us happy, Non...</td>\n",
       "      <td>33</td>\n",
       "      <td>[the, of, what, went wrong, theater, theatre, ...</td>\n",
       "      <td>[UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>dear sir or madam i am writing to complain abo...</td>\n",
       "      <td>(dear, sir, or, madam, i, am, writing, to, com...</td>\n",
       "      <td>[dear, sir, or, madam, i, am, writing, to, com...</td>\n",
       "      <td>[dear, sir, madam, writing, complain, show, di...</td>\n",
       "      <td>226</td>\n",
       "      <td>dear sir madam writing complain show disappoin...</td>\n",
       "      <td>[dear, sir, madam, write, complain, show, disa...</td>\n",
       "      <td>[ADJ, PROPN, CCONJ, PROPN, PRON, AUX, VERB, PA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document_Name                                           Response  \\\n",
       "0   doc2485.xml  Dear Helen I have received your letter which m...   \n",
       "1   doc1832.xml  Dear Sir, Last week I London for . During my s...   \n",
       "2    doc426.xml  Dear Helen Ryan: I am writing to answer the qu...   \n",
       "3   doc1826.xml  Dear Sir, I'm writing to you to complain about...   \n",
       "4   doc1198.xml  Dear Sir or Madam, I am writing to complain ab...   \n",
       "\n",
       "                                            Mistakes  Number_of_Mistakes  \\\n",
       "0  [., is, make, The, attempt, invite, holidy, , ...                  20   \n",
       "1  [stayed in, holidays, show, was, see, diferent...                  15   \n",
       "2  [to, an other, august, rather, log cabins, its...                  12   \n",
       "3  [None, deceiveful, it, into, character, of, ad...                  25   \n",
       "4  [musical, which, it, didn't make us happy, Non...                  33   \n",
       "\n",
       "                                         Corrections  \\\n",
       "0  [,, ,, makes, For the, a, take you up on, invi...   \n",
       "1  [went to, a, holiday, were, seeing, different,...   \n",
       "2  [another, August, a, log cabin, it's, options,...   \n",
       "3  [deceitful, disappointing, actor, advertising,...   \n",
       "4  [the, of, what, went wrong, theater, theatre, ...   \n",
       "\n",
       "                                    Correction_Codes  Answer_Score  \\\n",
       "0  [RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...           2.3   \n",
       "1  [RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...           3.2   \n",
       "2  [UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]           4.3   \n",
       "3  [RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...           4.3   \n",
       "4  [UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...           3.2   \n",
       "\n",
       "                                    Cleaned_Response  \\\n",
       "0  dear helen i have received your letter which m...   \n",
       "1  dear sir last week i london for during my stay...   \n",
       "2  dear helen ryan i am writing to answer the que...   \n",
       "3  dear sir i'm writing to you to complain about ...   \n",
       "4  dear sir or madam i am writing to complain abo...   \n",
       "\n",
       "                                        NLP_Response  \\\n",
       "0  (dear, helen, i, have, received, your, letter,...   \n",
       "1  (dear, sir, last, week, i, london, for, during...   \n",
       "2  (dear, helen, ryan, i, am, writing, to, answer...   \n",
       "3  (dear, sir, i, 'm, writing, to, you, to, compl...   \n",
       "4  (dear, sir, or, madam, i, am, writing, to, com...   \n",
       "\n",
       "                               Cleaned_Response_List  \\\n",
       "0  [dear, helen, i, have, received, your, letter,...   \n",
       "1  [dear, sir, last, week, i, london, for, during...   \n",
       "2  [dear, helen, ryan, i, am, writing, to, answer...   \n",
       "3  [dear, sir, i'm, writing, to, you, to, complai...   \n",
       "4  [dear, sir, or, madam, i, am, writing, to, com...   \n",
       "\n",
       "                            Cleaned_Response_No_Stop  Number_of_Tokens  \\\n",
       "0  [dear, helen, received, letter, happy, first, ...               143   \n",
       "1  [dear, sir, last, week, london, stay, beautifu...               197   \n",
       "2  [dear, helen, ryan, writing, answer, questions...               152   \n",
       "3  [dear, sir, i'm, writing, complain, experience...               198   \n",
       "4  [dear, sir, madam, writing, complain, show, di...               226   \n",
       "\n",
       "                             Joined_Cleaned_Response  \\\n",
       "0  dear helen received letter happy first time li...   \n",
       "1  dear sir last week london stay beautiful city ...   \n",
       "2  dear helen ryan writing answer questions asked...   \n",
       "3  dear sir i'm writing complain experience theat...   \n",
       "4  dear sir madam writing complain show disappoin...   \n",
       "\n",
       "                                            PS_Stems  \\\n",
       "0  [dear, helen, receiv, letter, happi, first, ti...   \n",
       "1  [dear, sir, last, week, london, stay, beauti, ...   \n",
       "2  [dear, helen, ryan, write, answer, question, a...   \n",
       "3  [dear, sir, i, 'm, write, complain, experi, th...   \n",
       "4  [dear, sir, madam, write, complain, show, disa...   \n",
       "\n",
       "                                            POS_Tags  \n",
       "0  [ADJ, NOUN, PRON, AUX, VERB, PRON, NOUN, DET, ...  \n",
       "1  [ADJ, NOUN, ADJ, NOUN, PRON, VERB, ADP, ADP, P...  \n",
       "2  [ADJ, PROPN, NOUN, PRON, AUX, VERB, PART, VERB...  \n",
       "3  [ADJ, NOUN, PRON, AUX, VERB, ADP, PRON, PART, ...  \n",
       "4  [ADJ, PROPN, CCONJ, PROPN, PRON, AUX, VERB, PA...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting some features with spacy from the response variable\n",
    "\n",
    "# number of tokens is the only one I derive from the feature that includes stopwords\n",
    "fce_df[\"Number_of_Tokens\"] = [len(token) for token in fce_df.NLP_Response]\n",
    "\n",
    "# join the list of non-stopwords in Cleaned_Response_No_Stop\n",
    "# to be parsed by PorterStemmer\n",
    "def join_list(list_from_column):\n",
    "    return ' '.join(x for x in list_from_column)\n",
    "\n",
    "\n",
    "fce_df[\"Joined_Cleaned_Response\"] = fce_df.Cleaned_Response_No_Stop.apply(\n",
    "    join_list)\n",
    "\n",
    "# getting the stems\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# function to get the porter stemmer stems from column\n",
    "def get_ps_stems(text):\n",
    "    ps_stems = []\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    for token in tokenized_text:\n",
    "        ps_stems.append(ps.stem(token))\n",
    "    return ps_stems\n",
    "\n",
    "fce_df[\"PS_Stems\"] = fce_df.Joined_Cleaned_Response.apply(get_ps_stems)\n",
    "\n",
    "\n",
    "# pos tags from not cleaned (includes stopwords)\n",
    "def get_pos_tags(text):\n",
    "    pos_tags = []\n",
    "    for token in text:\n",
    "        pos_tags.append(token.pos_)\n",
    "    return pos_tags\n",
    "\n",
    "\n",
    "fce_df[\"POS_Tags\"] = fce_df.NLP_Response.apply(get_pos_tags)\n",
    "\n",
    "# check it out\n",
    "fce_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Splitting List Variables\n",
    "\n",
    "* Turned each of the following into a DataFrame using pd.get_dummies():\n",
    "    * Parts of speech tags\n",
    "    * Correction codes\n",
    "    * Entity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:31.884565Z",
     "start_time": "2021-08-23T02:00:30.207943Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here I go ahead and create the DataFrames that show the count\n",
    "# of the unique pos_tags, correction codes, and entity labels\n",
    "# for each student response\n",
    "\n",
    "parts_of_speech_df = pd.get_dummies(fce_df.POS_Tags.apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "correction_codes_df = pd.get_dummies(fce_df.Correction_Codes.apply(pd.Series).stack()).sum(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:31.906685Z",
     "start_time": "2021-08-23T02:00:31.886320Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2457 entries, 0 to 2456\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Document_Name             2457 non-null   object \n",
      " 1   Response                  2457 non-null   object \n",
      " 2   Mistakes                  2457 non-null   object \n",
      " 3   Number_of_Mistakes        2457 non-null   int64  \n",
      " 4   Corrections               2457 non-null   object \n",
      " 5   Correction_Codes          2457 non-null   object \n",
      " 6   Answer_Score              2457 non-null   float64\n",
      " 7   Cleaned_Response          2457 non-null   object \n",
      " 8   NLP_Response              2457 non-null   object \n",
      " 9   Cleaned_Response_List     2457 non-null   object \n",
      " 10  Cleaned_Response_No_Stop  2457 non-null   object \n",
      " 11  Number_of_Tokens          2457 non-null   int64  \n",
      " 12  Joined_Cleaned_Response   2457 non-null   object \n",
      " 13  PS_Stems                  2457 non-null   object \n",
      " 14  POS_Tags                  2457 non-null   object \n",
      "dtypes: float64(1), int64(2), object(12)\n",
      "memory usage: 288.1+ KB\n"
     ]
    }
   ],
   "source": [
    "fce_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.012421Z",
     "start_time": "2021-08-23T02:00:31.909167Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>Number_of_Mistakes</th>\n",
       "      <th>Corrections</th>\n",
       "      <th>Correction_Codes</th>\n",
       "      <th>Answer_Score</th>\n",
       "      <th>Cleaned_Response</th>\n",
       "      <th>NLP_Response</th>\n",
       "      <th>Cleaned_Response_List</th>\n",
       "      <th>Cleaned_Response_No_Stop</th>\n",
       "      <th>Number_of_Tokens</th>\n",
       "      <th>Joined_Cleaned_Response</th>\n",
       "      <th>PS_Stems</th>\n",
       "      <th>POS_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc2485.xml</td>\n",
       "      <td>Dear Helen I have received your letter which m...</td>\n",
       "      <td>[., is, make, The, attempt, invite, holidy, , ...</td>\n",
       "      <td>20</td>\n",
       "      <td>[,, ,, makes, For the, a, take you up on, invi...</td>\n",
       "      <td>[RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>dear helen i have received your letter which m...</td>\n",
       "      <td>(dear, helen, i, have, received, your, letter,...</td>\n",
       "      <td>[dear, helen, i, have, received, your, letter,...</td>\n",
       "      <td>[dear, helen, received, letter, happy, first, ...</td>\n",
       "      <td>143</td>\n",
       "      <td>dear helen received letter happy first time li...</td>\n",
       "      <td>[dear, helen, receiv, letter, happi, first, ti...</td>\n",
       "      <td>[ADJ, NOUN, PRON, AUX, VERB, PRON, NOUN, DET, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1832.xml</td>\n",
       "      <td>Dear Sir, Last week I London for . During my s...</td>\n",
       "      <td>[stayed in, holidays, show, was, see, diferent...</td>\n",
       "      <td>15</td>\n",
       "      <td>[went to, a, holiday, were, seeing, different,...</td>\n",
       "      <td>[RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>dear sir last week i london for during my stay...</td>\n",
       "      <td>(dear, sir, last, week, i, london, for, during...</td>\n",
       "      <td>[dear, sir, last, week, i, london, for, during...</td>\n",
       "      <td>[dear, sir, last, week, london, stay, beautifu...</td>\n",
       "      <td>197</td>\n",
       "      <td>dear sir last week london stay beautiful city ...</td>\n",
       "      <td>[dear, sir, last, week, london, stay, beauti, ...</td>\n",
       "      <td>[ADJ, NOUN, ADJ, NOUN, PRON, VERB, ADP, ADP, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc426.xml</td>\n",
       "      <td>Dear Helen Ryan: I am writing to answer the qu...</td>\n",
       "      <td>[to, an other, august, rather, log cabins, its...</td>\n",
       "      <td>12</td>\n",
       "      <td>[another, August, a, log cabin, it's, options,...</td>\n",
       "      <td>[UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]</td>\n",
       "      <td>4.3</td>\n",
       "      <td>dear helen ryan i am writing to answer the que...</td>\n",
       "      <td>(dear, helen, ryan, i, am, writing, to, answer...</td>\n",
       "      <td>[dear, helen, ryan, i, am, writing, to, answer...</td>\n",
       "      <td>[dear, helen, ryan, writing, answer, questions...</td>\n",
       "      <td>152</td>\n",
       "      <td>dear helen ryan writing answer questions asked...</td>\n",
       "      <td>[dear, helen, ryan, write, answer, question, a...</td>\n",
       "      <td>[ADJ, PROPN, NOUN, PRON, AUX, VERB, PART, VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1826.xml</td>\n",
       "      <td>Dear Sir, I'm writing to you to complain about...</td>\n",
       "      <td>[None, deceiveful, it, into, character, of, ad...</td>\n",
       "      <td>25</td>\n",
       "      <td>[deceitful, disappointing, actor, advertising,...</td>\n",
       "      <td>[RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>dear sir i'm writing to you to complain about ...</td>\n",
       "      <td>(dear, sir, i, 'm, writing, to, you, to, compl...</td>\n",
       "      <td>[dear, sir, i'm, writing, to, you, to, complai...</td>\n",
       "      <td>[dear, sir, i'm, writing, complain, experience...</td>\n",
       "      <td>198</td>\n",
       "      <td>dear sir i'm writing complain experience theat...</td>\n",
       "      <td>[dear, sir, i, 'm, write, complain, experi, th...</td>\n",
       "      <td>[ADJ, NOUN, PRON, AUX, VERB, ADP, PRON, PART, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1198.xml</td>\n",
       "      <td>Dear Sir or Madam, I am writing to complain ab...</td>\n",
       "      <td>[musical, which, it, didn't make us happy, Non...</td>\n",
       "      <td>33</td>\n",
       "      <td>[the, of, what, went wrong, theater, theatre, ...</td>\n",
       "      <td>[UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>dear sir or madam i am writing to complain abo...</td>\n",
       "      <td>(dear, sir, or, madam, i, am, writing, to, com...</td>\n",
       "      <td>[dear, sir, or, madam, i, am, writing, to, com...</td>\n",
       "      <td>[dear, sir, madam, writing, complain, show, di...</td>\n",
       "      <td>226</td>\n",
       "      <td>dear sir madam writing complain show disappoin...</td>\n",
       "      <td>[dear, sir, madam, write, complain, show, disa...</td>\n",
       "      <td>[ADJ, PROPN, CCONJ, PROPN, PRON, AUX, VERB, PA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>doc2311.xml</td>\n",
       "      <td>Modern technology been changing human life sin...</td>\n",
       "      <td>[have, the, many, eletricity, than, t.v., , wh...</td>\n",
       "      <td>14</td>\n",
       "      <td>[has, man, electricity, then, TV, . When, mill...</td>\n",
       "      <td>[AGV, UD, R, S, SX, RP, RP, S, RP, MP, UD, RV,...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>modern technology been changing human life sin...</td>\n",
       "      <td>(modern, technology, been, changing, human, li...</td>\n",
       "      <td>[modern, technology, been, changing, human, li...</td>\n",
       "      <td>[modern, technology, changing, human, life, si...</td>\n",
       "      <td>107</td>\n",
       "      <td>modern technology changing human life since fi...</td>\n",
       "      <td>[modern, technolog, chang, human, life, sinc, ...</td>\n",
       "      <td>[ADJ, NOUN, AUX, VERB, ADJ, NOUN, SCONJ, DET, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>doc2305.xml</td>\n",
       "      <td>The Home of the Future Dear Reader, I have dec...</td>\n",
       "      <td>[obey, ,, every thing, furiture, programm, jus...</td>\n",
       "      <td>13</td>\n",
       "      <td>[our, respond, everything, furniture, programm...</td>\n",
       "      <td>[MD, RV, UP, RP, S, S, W, RT, MD, MV, RN, CL, ...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>the home of the future dear reader i have deci...</td>\n",
       "      <td>(the, home, of, the, future, dear, reader, i, ...</td>\n",
       "      <td>[the, home, of, the, future, dear, reader, i, ...</td>\n",
       "      <td>[home, future, dear, reader, decided, describe...</td>\n",
       "      <td>173</td>\n",
       "      <td>home future dear reader decided describe home ...</td>\n",
       "      <td>[home, futur, dear, reader, decid, describ, ho...</td>\n",
       "      <td>[DET, NOUN, ADP, DET, ADJ, ADJ, NOUN, PRON, AU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>doc2463.xml</td>\n",
       "      <td>How modern technology changed your daily life!...</td>\n",
       "      <td>[place, since, TV, None, washing-machine, avai...</td>\n",
       "      <td>20</td>\n",
       "      <td>[importance, in, beginning of, ,, TVs, washing...</td>\n",
       "      <td>[RN, RT, MN, MP, FN, FN, UP, FJ, MP, S, MN, MP...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>how modern technology changed your daily life ...</td>\n",
       "      <td>(how, modern, technology, changed, your, daily...</td>\n",
       "      <td>[how, modern, technology, changed, your, daily...</td>\n",
       "      <td>[modern, technology, changed, daily, life, beg...</td>\n",
       "      <td>205</td>\n",
       "      <td>modern technology changed daily life begin i'd...</td>\n",
       "      <td>[modern, technolog, chang, daili, life, begin,...</td>\n",
       "      <td>[ADV, ADJ, NOUN, VERB, PRON, ADJ, NOUN, PART, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>doc365.xml</td>\n",
       "      <td>How has modern technology changed your daily l...</td>\n",
       "      <td>[had a gigantic improvement, all became, invol...</td>\n",
       "      <td>17</td>\n",
       "      <td>[has improved gigantically, have all become, i...</td>\n",
       "      <td>[AS, TV, AGV, MD, RD, RA, S, UD, AGV, FN, AGA,...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>how has modern technology changed your daily l...</td>\n",
       "      <td>(how, has, modern, technology, changed, your, ...</td>\n",
       "      <td>[how, has, modern, technology, changed, your, ...</td>\n",
       "      <td>[modern, technology, changed, daily, life, kno...</td>\n",
       "      <td>182</td>\n",
       "      <td>modern technology changed daily life know tech...</td>\n",
       "      <td>[modern, technolog, chang, daili, life, know, ...</td>\n",
       "      <td>[ADV, AUX, ADJ, NOUN, VERB, PRON, ADJ, NOUN, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>doc403.xml</td>\n",
       "      <td>\"Shopping is not always enjoyable\". Before we ...</td>\n",
       "      <td>[statemant, about, stands for, luxuary, contes...</td>\n",
       "      <td>22</td>\n",
       "      <td>[statement, means, luxury, context, on, what y...</td>\n",
       "      <td>[S, UT, RV, S, RN, RT, UT, W, R, S, MQ, RT, RN...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>shopping is not always enjoyable before we can...</td>\n",
       "      <td>(shopping, is, not, always, enjoyable, before,...</td>\n",
       "      <td>[shopping, is, not, always, enjoyable, before,...</td>\n",
       "      <td>[shopping, always, enjoyable, give, opinions, ...</td>\n",
       "      <td>206</td>\n",
       "      <td>shopping always enjoyable give opinions make s...</td>\n",
       "      <td>[shop, alway, enjoy, give, opinion, make, sure...</td>\n",
       "      <td>[NOUN, AUX, PART, ADV, ADJ, ADP, PRON, AUX, VE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_Name                                           Response  \\\n",
       "0      doc2485.xml  Dear Helen I have received your letter which m...   \n",
       "1      doc1832.xml  Dear Sir, Last week I London for . During my s...   \n",
       "2       doc426.xml  Dear Helen Ryan: I am writing to answer the qu...   \n",
       "3      doc1826.xml  Dear Sir, I'm writing to you to complain about...   \n",
       "4      doc1198.xml  Dear Sir or Madam, I am writing to complain ab...   \n",
       "...            ...                                                ...   \n",
       "2452   doc2311.xml  Modern technology been changing human life sin...   \n",
       "2453   doc2305.xml  The Home of the Future Dear Reader, I have dec...   \n",
       "2454   doc2463.xml  How modern technology changed your daily life!...   \n",
       "2455    doc365.xml  How has modern technology changed your daily l...   \n",
       "2456    doc403.xml  \"Shopping is not always enjoyable\". Before we ...   \n",
       "\n",
       "                                               Mistakes  Number_of_Mistakes  \\\n",
       "0     [., is, make, The, attempt, invite, holidy, , ...                  20   \n",
       "1     [stayed in, holidays, show, was, see, diferent...                  15   \n",
       "2     [to, an other, august, rather, log cabins, its...                  12   \n",
       "3     [None, deceiveful, it, into, character, of, ad...                  25   \n",
       "4     [musical, which, it, didn't make us happy, Non...                  33   \n",
       "...                                                 ...                 ...   \n",
       "2452  [have, the, many, eletricity, than, t.v., , wh...                  14   \n",
       "2453  [obey, ,, every thing, furiture, programm, jus...                  13   \n",
       "2454  [place, since, TV, None, washing-machine, avai...                  20   \n",
       "2455  [had a gigantic improvement, all became, invol...                  17   \n",
       "2456  [statemant, about, stands for, luxuary, contes...                  22   \n",
       "\n",
       "                                            Corrections  \\\n",
       "0     [,, ,, makes, For the, a, take you up on, invi...   \n",
       "1     [went to, a, holiday, were, seeing, different,...   \n",
       "2     [another, August, a, log cabin, it's, options,...   \n",
       "3     [deceitful, disappointing, actor, advertising,...   \n",
       "4     [the, of, what, went wrong, theater, theatre, ...   \n",
       "...                                                 ...   \n",
       "2452  [has, man, electricity, then, TV, . When, mill...   \n",
       "2453  [our, respond, everything, furniture, programm...   \n",
       "2454  [importance, in, beginning of, ,, TVs, washing...   \n",
       "2455  [has improved gigantically, have all become, i...   \n",
       "2456  [statement, means, luxury, context, on, what y...   \n",
       "\n",
       "                                       Correction_Codes  Answer_Score  \\\n",
       "0     [RP, MP, UV, AGV, MT, MD, RV, L, MV, S, RP, MD...           2.3   \n",
       "1     [RV, MD, AGN, UN, AGV, FV, S, FV, IV, R, UP, F...           3.2   \n",
       "2     [UT, RP, RP, UV, MD, AGN, MP, R, RV, W, S, RJ, S]           4.3   \n",
       "3     [RJ, DJ, UA, UT, RN, UT, RV, UT, S, R, RN, UJ,...           4.3   \n",
       "4     [UJ, MD, MT, RA, UA, R, SA, S, M, FV, RD, UY, ...           3.2   \n",
       "...                                                 ...           ...   \n",
       "2452  [AGV, UD, R, S, SX, RP, RP, S, RP, MP, UD, RV,...           3.2   \n",
       "2453  [MD, RV, UP, RP, S, S, W, RT, MD, MV, RN, CL, ...           5.1   \n",
       "2454  [RN, RT, MN, MP, FN, FN, UP, FJ, MP, S, MN, MP...           3.3   \n",
       "2455  [AS, TV, AGV, MD, RD, RA, S, UD, AGV, FN, AGA,...           3.3   \n",
       "2456  [S, UT, RV, S, RN, RT, UT, W, R, S, MQ, RT, RN...           4.2   \n",
       "\n",
       "                                       Cleaned_Response  \\\n",
       "0     dear helen i have received your letter which m...   \n",
       "1     dear sir last week i london for during my stay...   \n",
       "2     dear helen ryan i am writing to answer the que...   \n",
       "3     dear sir i'm writing to you to complain about ...   \n",
       "4     dear sir or madam i am writing to complain abo...   \n",
       "...                                                 ...   \n",
       "2452  modern technology been changing human life sin...   \n",
       "2453  the home of the future dear reader i have deci...   \n",
       "2454  how modern technology changed your daily life ...   \n",
       "2455  how has modern technology changed your daily l...   \n",
       "2456  shopping is not always enjoyable before we can...   \n",
       "\n",
       "                                           NLP_Response  \\\n",
       "0     (dear, helen, i, have, received, your, letter,...   \n",
       "1     (dear, sir, last, week, i, london, for, during...   \n",
       "2     (dear, helen, ryan, i, am, writing, to, answer...   \n",
       "3     (dear, sir, i, 'm, writing, to, you, to, compl...   \n",
       "4     (dear, sir, or, madam, i, am, writing, to, com...   \n",
       "...                                                 ...   \n",
       "2452  (modern, technology, been, changing, human, li...   \n",
       "2453  (the, home, of, the, future, dear, reader, i, ...   \n",
       "2454  (how, modern, technology, changed, your, daily...   \n",
       "2455  (how, has, modern, technology, changed, your, ...   \n",
       "2456  (shopping, is, not, always, enjoyable, before,...   \n",
       "\n",
       "                                  Cleaned_Response_List  \\\n",
       "0     [dear, helen, i, have, received, your, letter,...   \n",
       "1     [dear, sir, last, week, i, london, for, during...   \n",
       "2     [dear, helen, ryan, i, am, writing, to, answer...   \n",
       "3     [dear, sir, i'm, writing, to, you, to, complai...   \n",
       "4     [dear, sir, or, madam, i, am, writing, to, com...   \n",
       "...                                                 ...   \n",
       "2452  [modern, technology, been, changing, human, li...   \n",
       "2453  [the, home, of, the, future, dear, reader, i, ...   \n",
       "2454  [how, modern, technology, changed, your, daily...   \n",
       "2455  [how, has, modern, technology, changed, your, ...   \n",
       "2456  [shopping, is, not, always, enjoyable, before,...   \n",
       "\n",
       "                               Cleaned_Response_No_Stop  Number_of_Tokens  \\\n",
       "0     [dear, helen, received, letter, happy, first, ...               143   \n",
       "1     [dear, sir, last, week, london, stay, beautifu...               197   \n",
       "2     [dear, helen, ryan, writing, answer, questions...               152   \n",
       "3     [dear, sir, i'm, writing, complain, experience...               198   \n",
       "4     [dear, sir, madam, writing, complain, show, di...               226   \n",
       "...                                                 ...               ...   \n",
       "2452  [modern, technology, changing, human, life, si...               107   \n",
       "2453  [home, future, dear, reader, decided, describe...               173   \n",
       "2454  [modern, technology, changed, daily, life, beg...               205   \n",
       "2455  [modern, technology, changed, daily, life, kno...               182   \n",
       "2456  [shopping, always, enjoyable, give, opinions, ...               206   \n",
       "\n",
       "                                Joined_Cleaned_Response  \\\n",
       "0     dear helen received letter happy first time li...   \n",
       "1     dear sir last week london stay beautiful city ...   \n",
       "2     dear helen ryan writing answer questions asked...   \n",
       "3     dear sir i'm writing complain experience theat...   \n",
       "4     dear sir madam writing complain show disappoin...   \n",
       "...                                                 ...   \n",
       "2452  modern technology changing human life since fi...   \n",
       "2453  home future dear reader decided describe home ...   \n",
       "2454  modern technology changed daily life begin i'd...   \n",
       "2455  modern technology changed daily life know tech...   \n",
       "2456  shopping always enjoyable give opinions make s...   \n",
       "\n",
       "                                               PS_Stems  \\\n",
       "0     [dear, helen, receiv, letter, happi, first, ti...   \n",
       "1     [dear, sir, last, week, london, stay, beauti, ...   \n",
       "2     [dear, helen, ryan, write, answer, question, a...   \n",
       "3     [dear, sir, i, 'm, write, complain, experi, th...   \n",
       "4     [dear, sir, madam, write, complain, show, disa...   \n",
       "...                                                 ...   \n",
       "2452  [modern, technolog, chang, human, life, sinc, ...   \n",
       "2453  [home, futur, dear, reader, decid, describ, ho...   \n",
       "2454  [modern, technolog, chang, daili, life, begin,...   \n",
       "2455  [modern, technolog, chang, daili, life, know, ...   \n",
       "2456  [shop, alway, enjoy, give, opinion, make, sure...   \n",
       "\n",
       "                                               POS_Tags  \n",
       "0     [ADJ, NOUN, PRON, AUX, VERB, PRON, NOUN, DET, ...  \n",
       "1     [ADJ, NOUN, ADJ, NOUN, PRON, VERB, ADP, ADP, P...  \n",
       "2     [ADJ, PROPN, NOUN, PRON, AUX, VERB, PART, VERB...  \n",
       "3     [ADJ, NOUN, PRON, AUX, VERB, ADP, PRON, PART, ...  \n",
       "4     [ADJ, PROPN, CCONJ, PROPN, PRON, AUX, VERB, PA...  \n",
       "...                                                 ...  \n",
       "2452  [ADJ, NOUN, AUX, VERB, ADJ, NOUN, SCONJ, DET, ...  \n",
       "2453  [DET, NOUN, ADP, DET, ADJ, ADJ, NOUN, PRON, AU...  \n",
       "2454  [ADV, ADJ, NOUN, VERB, PRON, ADJ, NOUN, PART, ...  \n",
       "2455  [ADV, AUX, ADJ, NOUN, VERB, PRON, ADJ, NOUN, A...  \n",
       "2456  [NOUN, AUX, PART, ADV, ADJ, ADP, PRON, AUX, VE...  \n",
       "\n",
       "[2457 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fce_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.031345Z",
     "start_time": "2021-08-23T02:00:32.015297Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ADJ  ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  PROPN  \\\n",
       "0       8   12   10    9      4    5     1    21    0     9    32      3   \n",
       "1      13   30   13   12      4   26     0    30    4     7    28      3   \n",
       "2      10   15    8   12      5    8     1    22    0     7    25      4   \n",
       "3      12   19   17   16      2   18     0    30    1     9    36      3   \n",
       "4       9   22   18   12      9   20     0    33    0     8    40      7   \n",
       "...   ...  ...  ...  ...    ...  ...   ...   ...  ...   ...   ...    ...   \n",
       "2452    5   11    7    7      2   11     0    22    0     2    17      1   \n",
       "2453   16   18    8   16      8   17     1    37    1     5    21      0   \n",
       "2454   23   20   10   11     13   23     0    45    0     8    20      0   \n",
       "2455   16   20   17    8      6   20     0    47    0     8    13      0   \n",
       "2456   11   21    9   11      7   15     0    41    0    14    30      0   \n",
       "\n",
       "      PUNCT  SCONJ  SPACE  SYM  VERB  X  \n",
       "0         0      0      1    0    28  0  \n",
       "1         0      5      0    0    22  0  \n",
       "2         0      6      1    0    28  0  \n",
       "3         0      7      0    0    28  0  \n",
       "4         0      6      3    0    39  0  \n",
       "...     ...    ...    ...  ...   ... ..  \n",
       "2452      0      2      0    0    20  0  \n",
       "2453      0      2      1    0    22  0  \n",
       "2454      0      1      0    0    30  1  \n",
       "2455      0      5      1    0    21  0  \n",
       "2456      6      7      0    0    34  0  \n",
       "\n",
       "[2457 rows x 18 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts_of_speech_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.053207Z",
     "start_time": "2021-08-23T02:00:32.034291Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AG</th>\n",
       "      <th>AGA</th>\n",
       "      <th>AGD</th>\n",
       "      <th>AGN</th>\n",
       "      <th>AGQ</th>\n",
       "      <th>AGV</th>\n",
       "      <th>AS</th>\n",
       "      <th>CD</th>\n",
       "      <th>CE</th>\n",
       "      <th>CL</th>\n",
       "      <th>...</th>\n",
       "      <th>UD</th>\n",
       "      <th>UJ</th>\n",
       "      <th>UN</th>\n",
       "      <th>UP</th>\n",
       "      <th>UQ</th>\n",
       "      <th>UT</th>\n",
       "      <th>UV</th>\n",
       "      <th>UY</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2455 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AG  AGA  AGD  AGN  AGQ  AGV  AS  CD  CE  CL  ...  UD  UJ  UN  UP  UQ  \\\n",
       "0      0    0    0    0    0    1   0   0   0   0  ...   0   0   0   0   0   \n",
       "1      0    0    0    1    0    1   0   0   0   0  ...   0   0   1   1   0   \n",
       "2      0    0    0    1    0    0   0   0   0   0  ...   0   0   0   0   0   \n",
       "3      0    0    0    0    0    1   0   0   0   0  ...   0   1   0   0   0   \n",
       "4      0    0    0    0    0    0   0   0   0   0  ...   0   1   0   0   0   \n",
       "...   ..  ...  ...  ...  ...  ...  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "2452   0    0    0    0    0    1   0   0   0   0  ...   2   0   0   0   0   \n",
       "2453   0    0    0    0    0    0   0   0   0   1  ...   0   0   0   1   0   \n",
       "2454   0    0    0    0    0    2   0   0   0   0  ...   0   0   0   1   0   \n",
       "2455   0    1    0    0    1    2   1   0   0   0  ...   1   0   0   0   0   \n",
       "2456   0    0    0    0    0    0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "      UT  UV  UY  W  X  \n",
       "0      1   1   0  1  0  \n",
       "1      0   0   0  0  0  \n",
       "2      1   1   0  1  0  \n",
       "3      4   0   0  0  0  \n",
       "4      1   0   1  0  0  \n",
       "...   ..  ..  .. .. ..  \n",
       "2452   0   0   0  1  0  \n",
       "2453   0   0   0  2  0  \n",
       "2454   0   2   0  0  0  \n",
       "2455   0   0   0  0  0  \n",
       "2456   2   0   0  1  0  \n",
       "\n",
       "[2455 rows x 75 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Four Classes - Numerical Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.061424Z",
     "start_time": "2021-08-23T02:00:32.055373Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3, 3.2, 4.3, 3.1, 3.3, 4.1, 4.2, 5.2, 5.1, 2.2, 5.3, 2.1, 1.3,\n",
       "       1.1, 1.2, 2. ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fce_df.Answer_Score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.078942Z",
     "start_time": "2021-08-23T02:00:32.063849Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a new categorical variable\n",
    "fce_df[\"Answer_Score_Level\"] = \"Not_Assigned\"\n",
    "\n",
    "# assign the top quarter\n",
    "top_quarter_scores = [5.2, 5.1, 5.3]\n",
    "fce_df.loc[fce_df[\"Answer_Score\"].isin(top_quarter_scores),\n",
    "          [\"Answer_Score_Level\"]] = 0\n",
    "\n",
    "# second quarter\n",
    "second_quarter_scores = [4.1, 4.2, 4.3]\n",
    "fce_df.loc[fce_df[\"Answer_Score\"].isin(second_quarter_scores),\n",
    "          [\"Answer_Score_Level\"]] = 1\n",
    "\n",
    "# third quarter\n",
    "third_quarter_scores = [3.1, 3.2, 3.3]\n",
    "fce_df.loc[fce_df[\"Answer_Score\"].isin(third_quarter_scores),\n",
    "          [\"Answer_Score_Level\"]] = 2\n",
    "\n",
    "# bottom quarter\n",
    "bottom_quarter_scores = [1.1, 1.2, 1.3, 2., 2.1, 2.2, 2.3]\n",
    "fce_df.loc[fce_df[\"Answer_Score\"].isin(bottom_quarter_scores),\n",
    "          [\"Answer_Score_Level\"]] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.089158Z",
     "start_time": "2021-08-23T02:00:32.080821Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    960\n",
       "1    665\n",
       "3    505\n",
       "0    327\n",
       "Name: Answer_Score_Level, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fce_df.Answer_Score_Level.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Four Classes - Stastical Quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.428690Z",
     "start_time": "2021-08-23T02:00:32.092412Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a new categorical variable\n",
    "fce_df[\"Answer_Score_Quarter\"] = \"Not_Assigned\"\n",
    "\n",
    "# assign the top quarter\n",
    "fce_df.loc[fce_df[\"Answer_Score\"] >= 4.2,\n",
    "          [\"Answer_Score_Quarter\"]] = 0\n",
    "\n",
    "# second quarter\n",
    "fce_df.loc[(fce_df[\"Answer_Score\"] < 4.2)\n",
    "           & (fce_df[\"Answer_Score\"] >= 3.3),\n",
    "           \"Answer_Score_Quarter\"] = 1\n",
    "\n",
    "# third quarter\n",
    "fce_df.loc[(fce_df[\"Answer_Score\"] < 3.3)\n",
    "           & (fce_df[\"Answer_Score\"] >= 3.1),\n",
    "           \"Answer_Score_Quarter\"] = 2\n",
    "\n",
    "# bottom quarter\n",
    "fce_df.loc[fce_df[\"Answer_Score\"] < 3.1,\n",
    "           [\"Answer_Score_Quarter\"]] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:32.435928Z",
     "start_time": "2021-08-23T02:00:32.430372Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    736\n",
       "2    619\n",
       "1    597\n",
       "3    505\n",
       "Name: Answer_Score_Quarter, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fce_df.Answer_Score_Quarter.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## BOW Method for Word Uni and Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Most Common Ngrams by Sum of Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:33.038674Z",
     "start_time": "2021-08-23T02:00:32.438612Z"
    },
    "cell_style": "center",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create unigrams\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "X = vectorizer.fit_transform(fce_df[\"PS_Stems\"])\n",
    "uni_word_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# drop na\n",
    "uni_word_df = uni_word_df.drop(uni_word_df[uni_word_df.isna().any(axis=1)].index).reset_index(drop=True)\n",
    "\n",
    "# drop some weird characters\n",
    "uni_word_df = uni_word_df.drop([\"'\", \"''\", \")\", \"*\", \";\", \"``\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:43.213427Z",
     "start_time": "2021-08-23T02:00:33.040327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create bigrams\n",
    "fce_df[\"Joined_PS_Stems\"] = fce_df.PS_Stems.apply(\n",
    "    join_list) # join the ps stems list into a string\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(fce_df[\"Joined_PS_Stems\"])\n",
    "bi_word_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# drop na\n",
    "bi_word_df = bi_word_df.drop(bi_word_df[bi_word_df.isna().any(axis=1)].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now for both the unigram and bigram DataFrames I'm going to get the sum of each column so we can cut out the least common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.528307Z",
     "start_time": "2021-08-23T02:00:43.316592Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create function to get sums from all columns in our ngram DataFrames\n",
    "def get_sums(dataframe):\n",
    "    sum_list = []\n",
    "    for column in dataframe.columns:\n",
    "        sum_list.append(dataframe[\"{}\".format(column)].sum())\n",
    "    return sum_list\n",
    "\n",
    "# apply the function to both ngram DataFrames\n",
    "uni_sums = get_sums(uni_word_df)\n",
    "bi_sums = get_sums(bi_word_df)\n",
    "\n",
    "# create new DataFrames to view the sums and columns\n",
    "uni_sum_df = pd.DataFrame({\"Unigram\": uni_word_df.columns,\n",
    "                         \"Sum\": uni_sums})\n",
    "\n",
    "bi_sum_df = pd.DataFrame({\"Bigram\": bi_word_df.columns,\n",
    "                         \"Sum\": bi_sums})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I *really* don't like all these contractions. They're getting treating as their own word, which makes sense, but they are also very common without much meaning since they're essentially stop words intertwined into other words. I'm going to cut out any \"stems\" that originate from a contraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.606383Z",
     "start_time": "2021-08-23T02:00:52.529882Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# grab the column headers that contain an apostrophe\n",
    "contraction_uni_headers = uni_sum_df[uni_sum_df.Unigram.str.contains(\"'\")]\n",
    "contraction_bi_headers = bi_sum_df[bi_sum_df.Bigram.str.contains(\"'\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.617722Z",
     "start_time": "2021-08-23T02:00:52.608134Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unigram</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'anitkabir</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'art</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'bigmouth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>mc'donald</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>n't</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>o'clock</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>smith'th</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>you'llmayb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unigram  Sum\n",
       "0             'a    1\n",
       "1           'all    1\n",
       "2     'anitkabir    2\n",
       "3           'art    1\n",
       "4      'bigmouth    1\n",
       "...          ...  ...\n",
       "3202   mc'donald    1\n",
       "3431         n't  274\n",
       "3558     o'clock   64\n",
       "4720    smith'th    1\n",
       "5800  you'llmayb    1\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contraction_uni_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.628109Z",
     "start_time": "2021-08-23T02:00:52.620232Z"
    },
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Bigram, Sum]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contraction_bi_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "source": [
    "Kind of weird that the bigram DataFrame didn't have any apostrophes. I think it's in the way I used the CountVectorizer. For the bigram one I used analyzer=\"word\" but for the unigram I used a method found on StackOverflow since the column I was extracting the unigrams from was a spacy object. Not going to look into it further for the purposes of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.635073Z",
     "start_time": "2021-08-23T02:00:52.630213Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get rid of the contractions\n",
    "uni_sum_df = uni_sum_df.drop(contraction_uni_headers.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "source": [
    "I would say for each ngram DataFrame we want the 100 most common words since the number of features needs to be less than 2000 and I still have other to include. This is going to be a *very* small percentage for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.888751Z",
     "start_time": "2021-08-23T02:00:52.637418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create DataFrames with the header names of those that\n",
    "# do not fit the criteria of top common\n",
    "top_common_uni = uni_sum_df[uni_sum_df.Sum > 600]\n",
    "top_common_bi = bi_sum_df[bi_sum_df.Sum > 90]\n",
    "\n",
    "not_common_uni = uni_sum_df[uni_sum_df.Sum <= 600]\n",
    "not_common_bi = bi_sum_df[bi_sum_df.Sum <= 150]\n",
    "\n",
    "# now we take the header names from the top common DataFrames\n",
    "# and iterate through them to remove from from our original\n",
    "# uni and bigram DataFrames\n",
    "\n",
    "uni_to_remove = list(not_common_uni.Unigram)\n",
    "bi_to_remove = list(not_common_bi.Bigram)\n",
    "\n",
    "# remove non-common words\n",
    "uni_word_df = uni_word_df.drop(uni_to_remove, axis=1)\n",
    "bi_word_df = bi_word_df.drop(bi_to_remove, axis=1)\n",
    "\n",
    "# also remove the contractions from the unigram DataFrame\n",
    "uni_word_df = uni_word_df.drop(list(contraction_uni_headers.Unigram), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.908894Z",
     "start_time": "2021-08-23T02:00:52.890299Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activ</th>\n",
       "      <th>advertis</th>\n",
       "      <th>also</th>\n",
       "      <th>ask</th>\n",
       "      <th>chang</th>\n",
       "      <th>cloth</th>\n",
       "      <th>concert</th>\n",
       "      <th>could</th>\n",
       "      <th>day</th>\n",
       "      <th>dear</th>\n",
       "      <th>...</th>\n",
       "      <th>theatr</th>\n",
       "      <th>thing</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>us</th>\n",
       "      <th>use</th>\n",
       "      <th>want</th>\n",
       "      <th>would</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activ  advertis  also  ask  chang  cloth  concert  could  day  dear  \\\n",
       "0         0         0     0    1      0      0        0      0    0     1   \n",
       "1         0         4     2    0      0      0        0      0    0     1   \n",
       "2         1         0     2    1      0      1        0      0    0     1   \n",
       "3         0         0     1    0      2      0        0      1    0     1   \n",
       "4         0         1     0    0      0      0        0      0    0     1   \n",
       "...     ...       ...   ...  ...    ...    ...      ...    ...  ...   ...   \n",
       "2452      0         0     0    0      1      0        0      0    0     0   \n",
       "2453      0         0     0    0      0      0        0      1    0     1   \n",
       "2454      0         0     1    0      3      0        0      0    0     0   \n",
       "2455      0         0     2    0      1      0        0      0    0     0   \n",
       "2456      0         0     0    0      1      2        0      1    1     0   \n",
       "\n",
       "      ...  theatr  thing  think  time  us  use  want  would  write  year  \n",
       "0     ...       0      0      2     1   0    2     0      3      0     1  \n",
       "1     ...       3      1      1     0   0    0     0      0      0     0  \n",
       "2     ...       0      0      0     0   0    0     0      4      1     0  \n",
       "3     ...       3      0      0     1   0    0     0      1      1     0  \n",
       "4     ...       1      0      1     2   2    0     1      2      1     0  \n",
       "...   ...     ...    ...    ...   ...  ..  ...   ...    ...    ...   ...  \n",
       "2452  ...       0      0      0     0   0    2     0      0      0     0  \n",
       "2453  ...       0      0      0     0   0    0     0      0      0     1  \n",
       "2454  ...       0      0      0     1   0    1     1      0      0     1  \n",
       "2455  ...       0      1      0     0   1    0     0      0      0     1  \n",
       "2456  ...       0      0      0     2   0    1     0      0      0     0  \n",
       "\n",
       "[2457 rows x 57 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:00:52.930759Z",
     "start_time": "2021-08-23T02:00:52.910792Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alway enjoy</th>\n",
       "      <th>camp california</th>\n",
       "      <th>circl theatr</th>\n",
       "      <th>daili life</th>\n",
       "      <th>danni brook</th>\n",
       "      <th>dear kim</th>\n",
       "      <th>dear mr</th>\n",
       "      <th>dear sir</th>\n",
       "      <th>discount avail</th>\n",
       "      <th>fashion leisur</th>\n",
       "      <th>...</th>\n",
       "      <th>pop concert</th>\n",
       "      <th>restaur close</th>\n",
       "      <th>shop alway</th>\n",
       "      <th>show start</th>\n",
       "      <th>theatr restaur</th>\n",
       "      <th>travel juli</th>\n",
       "      <th>two week</th>\n",
       "      <th>unfortun pat</th>\n",
       "      <th>would like</th>\n",
       "      <th>would prefer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alway enjoy  camp california  circl theatr  daili life  danni brook  \\\n",
       "0               0                0             0           0            0   \n",
       "1               0                0             0           0            1   \n",
       "2               0                1             0           0            0   \n",
       "3               0                0             0           0            1   \n",
       "4               0                0             0           0            1   \n",
       "...           ...              ...           ...         ...          ...   \n",
       "2452            0                0             0           0            0   \n",
       "2453            0                0             0           0            0   \n",
       "2454            0                0             0           2            0   \n",
       "2455            0                0             0           1            0   \n",
       "2456            2                0             0           0            0   \n",
       "\n",
       "      dear kim  dear mr  dear sir  discount avail  fashion leisur  ...  \\\n",
       "0            0        0         0               0               0  ...   \n",
       "1            0        0         1               1               0  ...   \n",
       "2            0        0         0               0               0  ...   \n",
       "3            0        0         1               0               0  ...   \n",
       "4            0        0         1               0               0  ...   \n",
       "...        ...      ...       ...             ...             ...  ...   \n",
       "2452         0        0         0               0               0  ...   \n",
       "2453         0        0         0               0               0  ...   \n",
       "2454         0        0         0               0               0  ...   \n",
       "2455         0        0         0               0               0  ...   \n",
       "2456         0        0         0               0               0  ...   \n",
       "\n",
       "      pop concert  restaur close  shop alway  show start  theatr restaur  \\\n",
       "0               0              0           0           0               0   \n",
       "1               0              1           0           0               0   \n",
       "2               0              0           0           0               0   \n",
       "3               0              0           0           1               0   \n",
       "4               0              1           0           1               1   \n",
       "...           ...            ...         ...         ...             ...   \n",
       "2452            0              0           0           0               0   \n",
       "2453            0              0           0           0               0   \n",
       "2454            0              0           0           0               0   \n",
       "2455            0              0           0           0               0   \n",
       "2456            0              0           2           0               0   \n",
       "\n",
       "      travel juli  two week  unfortun pat  would like  would prefer  \n",
       "0               0         0             0           2             1  \n",
       "1               0         0             0           0             0  \n",
       "2               0         0             0           2             1  \n",
       "3               0         0             0           0             0  \n",
       "4               0         0             0           1             0  \n",
       "...           ...       ...           ...         ...           ...  \n",
       "2452            0         0             0           0             0  \n",
       "2453            0         0             0           0             0  \n",
       "2454            0         0             0           0             0  \n",
       "2455            0         0             0           0             0  \n",
       "2456            0         0             0           0             0  \n",
       "\n",
       "[2457 rows x 39 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_word_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Most Weighted Ngrams by TF-IDF Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:33:02.149892Z",
     "start_time": "2021-08-23T02:33:01.027327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# apply tfidf to the joined porter stems\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create DataFrames of uni and bigrams with their tf-idfs\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(fce_df[\"Joined_PS_Stems\"])\n",
    "uni_tfidf_word_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "bi_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X_bi = bi_vectorizer.fit_transform(fce_df[\"Joined_PS_Stems\"])\n",
    "bi_tfidf_word_df = pd.DataFrame(X_bi.toarray(), columns=bi_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:07:34.452286Z",
     "start_time": "2021-08-23T02:07:34.448927Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create function to get the average of all weights for each word tfidf\n",
    "def get_means(dataframe):\n",
    "    mean_list = []\n",
    "    for column in dataframe.columns:\n",
    "        mean_list.append(dataframe[\"{}\".format(column)].mean())\n",
    "    return mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:38:38.787230Z",
     "start_time": "2021-08-23T02:38:32.594162Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the function to the ngram DataFrames\n",
    "uni_tfidf_means_list = get_means(uni_tfidf_word_df)\n",
    "bi_tfidf_means_list = get_means(bi_tfidf_word_df)\n",
    "\n",
    "# create DataFrame from the list of uni tfidf means\n",
    "uni_tfidf_means_df = pd.DataFrame({\"Unigram\": uni_tfidf_word_df.columns,\n",
    "                                  \"Mean\": uni_tfidf_means_list})\n",
    "\n",
    "bi_tfidf_means_df = pd.DataFrame({\"Bigram\": bi_tfidf_word_df.columns,\n",
    "                                 \"Mean\": bi_tfidf_means_list})\n",
    "\n",
    "# get the top 46 weighted unigrams\n",
    "top_common_tfidf_uni_means_df = uni_tfidf_means_df[uni_tfidf_means_df.Mean > 0.0184]\n",
    "not_top_common_tfidf_uni_means_df = uni_tfidf_means_df[uni_tfidf_means_df.Mean <= 0.0184]\n",
    "tfidf_uni_to_remove = list(not_top_common_tfidf_uni_means_df.Unigram)\n",
    "top_common_tfidf_uni_word_df = uni_tfidf_word_df.drop(tfidf_uni_to_remove, axis=1)\n",
    "\n",
    "# get the top 46 weighted bigrams\n",
    "top_common_tfidf_bi_means_df = bi_tfidf_means_df[bi_tfidf_means_df.Mean > 0.0035]\n",
    "not_top_common_tfidf_bi_means_df = bi_tfidf_means_df[bi_tfidf_means_df.Mean <=0.0035]\n",
    "tfidf_bi_to_remove = list(not_top_common_tfidf_bi_means_df.Bigram)\n",
    "top_common_tfidf_bi_word_df = bi_tfidf_word_df.drop(tfidf_bi_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## BOW Method for Parts-of-Speech Uni, Bi, and Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Most Common Ngrams by Sum of Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:39:18.486685Z",
     "start_time": "2021-08-23T03:39:17.565322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create pos unigrams\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "X = vectorizer.fit_transform(fce_df[\"POS_Tags\"])\n",
    "uni_pos_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# create pos bigrams\n",
    "fce_df[\"Joined_POS_Tags\"] = fce_df.POS_Tags.apply(\n",
    "    join_list)\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(fce_df[\"Joined_POS_Tags\"])\n",
    "bi_pos_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# create pos trigrams\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(3,3))\n",
    "X = vectorizer.fit_transform(fce_df[\"Joined_POS_Tags\"])\n",
    "tri_pos_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:44:34.599565Z",
     "start_time": "2021-08-23T03:44:34.583112Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# apply the function to both ngram DataFrames\n",
    "bi_pos_sums = get_sums(bi_pos_df)\n",
    "tri_pos_sums = get_sums(tri_pos_df)\n",
    "\n",
    "# create new DataFrames to view the sums and columns\n",
    "bi_sum_df = pd.DataFrame({\"Bigram\": bi_pos_df.columns,\n",
    "                         \"Sum\": bi_pos_sums})\n",
    "tri_sum_df = pd.DataFrame({\"Trigram\": tri_pos_df.columns,\n",
    "                         \"Sum\": tri_pos_sums})\n",
    "\n",
    "# most common and not most common pos bigrams\n",
    "top_common_bi_pos = bi_sum_df[bi_sum_df.Sum > 6000]\n",
    "not_common_bi_pos = bi_sum_df[bi_sum_df.Sum <= 6000]\n",
    "\n",
    "# create DataFrame of the most common pos trigrams\n",
    "# and the not most common\n",
    "top_common_tri_pos = tri_sum_df[tri_sum_df.Sum > 3000]\n",
    "not_common_tri_pos = tri_sum_df[tri_sum_df.Sum <= 3000]\n",
    "\n",
    "# create list to iterate through original bi and tri pos DataFrame and then remove\n",
    "bi_pos_to_remove = list(not_common_bi_pos.Bigram)\n",
    "tri_pos_to_remove = list(not_common_tri_pos.Trigram)\n",
    "bi_pos_df = bi_pos_df.drop(bi_pos_to_remove, axis=1)\n",
    "tri_pos_df = tri_pos_df.drop(tri_pos_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:44:34.845086Z",
     "start_time": "2021-08-23T03:44:34.829596Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ADJ  ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  PROPN  \\\n",
       "0       8   12   10    9      4    5     1    21    0     9    32      3   \n",
       "1      13   30   13   12      4   26     0    30    4     7    28      3   \n",
       "2      10   15    8   12      5    8     1    22    0     7    25      4   \n",
       "3      12   19   17   16      2   18     0    30    1     9    36      3   \n",
       "4       9   22   18   12      9   20     0    33    0     8    40      7   \n",
       "...   ...  ...  ...  ...    ...  ...   ...   ...  ...   ...   ...    ...   \n",
       "2452    5   11    7    7      2   11     0    22    0     2    17      1   \n",
       "2453   16   18    8   16      8   17     1    37    1     5    21      0   \n",
       "2454   23   20   10   11     13   23     0    45    0     8    20      0   \n",
       "2455   16   20   17    8      6   20     0    47    0     8    13      0   \n",
       "2456   11   21    9   11      7   15     0    41    0    14    30      0   \n",
       "\n",
       "      PUNCT  SCONJ  SPACE  SYM  VERB  X  \n",
       "0         0      0      1    0    28  0  \n",
       "1         0      5      0    0    22  0  \n",
       "2         0      6      1    0    28  0  \n",
       "3         0      7      0    0    28  0  \n",
       "4         0      6      3    0    39  0  \n",
       "...     ...    ...    ...  ...   ... ..  \n",
       "2452      0      2      0    0    20  0  \n",
       "2453      0      2      1    0    22  0  \n",
       "2454      0      1      0    0    30  1  \n",
       "2455      0      5      1    0    21  0  \n",
       "2456      6      7      0    0    34  0  \n",
       "\n",
       "[2457 rows x 18 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:44:35.185387Z",
     "start_time": "2021-08-23T03:44:35.165011Z"
    },
    "cell_style": "split",
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj noun</th>\n",
       "      <th>adp det</th>\n",
       "      <th>adp noun</th>\n",
       "      <th>adp pron</th>\n",
       "      <th>adv pron</th>\n",
       "      <th>aux verb</th>\n",
       "      <th>det adj</th>\n",
       "      <th>det noun</th>\n",
       "      <th>noun adp</th>\n",
       "      <th>noun cconj</th>\n",
       "      <th>...</th>\n",
       "      <th>part verb</th>\n",
       "      <th>pron aux</th>\n",
       "      <th>pron noun</th>\n",
       "      <th>pron verb</th>\n",
       "      <th>sconj pron</th>\n",
       "      <th>verb adp</th>\n",
       "      <th>verb adv</th>\n",
       "      <th>verb det</th>\n",
       "      <th>verb part</th>\n",
       "      <th>verb pron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adj noun  adp det  adp noun  adp pron  adv pron  aux verb  det adj  \\\n",
       "0            3        1         4         3         2         5        0   \n",
       "1            9       12         2         9         2         5        5   \n",
       "2            5        3         6         3         0         7        1   \n",
       "3            6        5         3         9         5         8        5   \n",
       "4            5        7         2         7         2         8        2   \n",
       "...        ...      ...       ...       ...       ...       ...      ...   \n",
       "2452         4        5         4         1         5         4        1   \n",
       "2453        11        6         1         6         3        11        4   \n",
       "2454        19        6         8         3         1         7        8   \n",
       "2455        11        9         8         1         2         4        8   \n",
       "2456         4        7         8         3         1         5        2   \n",
       "\n",
       "      det noun  noun adp  noun cconj  ...  part verb  pron aux  pron noun  \\\n",
       "0            4         4           2  ...          9         7          5   \n",
       "1           15         8           1  ...          6         9          3   \n",
       "2            6         5           3  ...          7        10          1   \n",
       "3           10         8           0  ...          6         8          6   \n",
       "4           11         4           4  ...          7        10          6   \n",
       "...        ...       ...         ...  ...        ...       ...        ...   \n",
       "2452         8         5           1  ...          2         1          4   \n",
       "2453         9         7           6  ...          5         6          6   \n",
       "2454        11        10          11  ...          7         6          3   \n",
       "2455         9         9           4  ...          6         0          1   \n",
       "2456         7         8           4  ...         11         6          5   \n",
       "\n",
       "      pron verb  sconj pron  verb adp  verb adv  verb det  verb part  \\\n",
       "0            14           0         4         2         2          5   \n",
       "1             7           2         8         2         5          2   \n",
       "2            10           4         4         4         2          6   \n",
       "3             9           5         4         3         7          3   \n",
       "4            17           4         9         6         8          4   \n",
       "...         ...         ...       ...       ...       ...        ...   \n",
       "2452         10           0         5         3         3          0   \n",
       "2453          4           0         5         2         2          3   \n",
       "2454          5           0         6         2         6          3   \n",
       "2455          7           2         3         4         5          0   \n",
       "2456         11           6         4         3         4          6   \n",
       "\n",
       "      verb pron  \n",
       "0             8  \n",
       "1             2  \n",
       "2             3  \n",
       "3             5  \n",
       "4             4  \n",
       "...         ...  \n",
       "2452          3  \n",
       "2453          5  \n",
       "2454          7  \n",
       "2455          3  \n",
       "2456         10  \n",
       "\n",
       "[2457 rows x 21 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:44:36.455357Z",
     "start_time": "2021-08-23T03:44:36.440630Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adp det noun</th>\n",
       "      <th>adp pron noun</th>\n",
       "      <th>adv pron verb</th>\n",
       "      <th>det adj noun</th>\n",
       "      <th>det noun adp</th>\n",
       "      <th>det noun pron</th>\n",
       "      <th>noun adp det</th>\n",
       "      <th>noun adp noun</th>\n",
       "      <th>noun pron aux</th>\n",
       "      <th>noun pron verb</th>\n",
       "      <th>part verb pron</th>\n",
       "      <th>pron aux verb</th>\n",
       "      <th>pron verb det</th>\n",
       "      <th>pron verb part</th>\n",
       "      <th>pron verb pron</th>\n",
       "      <th>verb adp det</th>\n",
       "      <th>verb det noun</th>\n",
       "      <th>verb part verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2457 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adp det noun  adp pron noun  adv pron verb  det adj noun  det noun adp  \\\n",
       "0                1              2              2             0             2   \n",
       "1                8              3              1             4             4   \n",
       "2                3              1              0             1             2   \n",
       "3                3              4              3             4             2   \n",
       "4                5              4              2             2             1   \n",
       "...            ...            ...            ...           ...           ...   \n",
       "2452             4              0              5             0             0   \n",
       "2453             4              3              0             3             5   \n",
       "2454             4              1              1             8             4   \n",
       "2455             4              0              2             6             1   \n",
       "2456             6              0              1             2             1   \n",
       "\n",
       "      det noun pron  noun adp det  noun adp noun  noun pron aux  \\\n",
       "0                 2             1              1              4   \n",
       "1                 3             5              0              1   \n",
       "2                 3             1              1              5   \n",
       "3                 3             2              2              3   \n",
       "4                 1             0              0              2   \n",
       "...             ...           ...            ...            ...   \n",
       "2452              2             4              1              0   \n",
       "2453              0             4              0              1   \n",
       "2454              0             4              4              3   \n",
       "2455              1             3              5              0   \n",
       "2456              1             2              4              2   \n",
       "\n",
       "      noun pron verb  part verb pron  pron aux verb  pron verb det  \\\n",
       "0                  5               3              4              0   \n",
       "1                  3               0              4              0   \n",
       "2                  5               0              6              1   \n",
       "3                  1               0              4              3   \n",
       "4                  7               2              6              3   \n",
       "...              ...             ...            ...            ...   \n",
       "2452               3               0              0              1   \n",
       "2453               1               1              5              0   \n",
       "2454               1               0              3              1   \n",
       "2455               3               0              0              4   \n",
       "2456               2               3              3              0   \n",
       "\n",
       "      pron verb part  pron verb pron  verb adp det  verb det noun  \\\n",
       "0                  4               4             0              2   \n",
       "1                  1               2             4              4   \n",
       "2                  2               1             1              1   \n",
       "3                  1               2             1              3   \n",
       "4                  2               0             3              3   \n",
       "...              ...             ...           ...            ...   \n",
       "2452               0               3             1              3   \n",
       "2453               1               1             0              1   \n",
       "2454               0               3             1              4   \n",
       "2455               0               1             1              2   \n",
       "2456               5               4             2              0   \n",
       "\n",
       "      verb part verb  \n",
       "0                  5  \n",
       "1                  2  \n",
       "2                  6  \n",
       "3                  3  \n",
       "4                  4  \n",
       "...              ...  \n",
       "2452               0  \n",
       "2453               3  \n",
       "2454               3  \n",
       "2455               0  \n",
       "2456               4  \n",
       "\n",
       "[2457 rows x 18 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Most Weighted Ngrams by TF-IDF Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:31:23.549257Z",
     "start_time": "2021-08-23T03:31:22.562869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create DataFrames of pos uni, bi, and trigrams with their tf-idfs\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(fce_df[\"Joined_POS_Tags\"])\n",
    "uni_tfidf_pos_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "bi_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X_bi = bi_vectorizer.fit_transform(fce_df[\"Joined_POS_Tags\"])\n",
    "bi_tfidf_pos_df = pd.DataFrame(X_bi.toarray(), columns=bi_vectorizer.get_feature_names())\n",
    "\n",
    "tri_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(3,3))\n",
    "X_tri = tri_vectorizer.fit_transform(fce_df[\"Joined_POS_Tags\"])\n",
    "tri_tfidf_pos_df = pd.DataFrame(X_tri.toarray(), columns=tri_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:31:23.554460Z",
     "start_time": "2021-08-23T03:31:23.551316Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create function to get the average of all weights for each word tfidf\n",
    "def get_means(dataframe):\n",
    "    mean_list = []\n",
    "    for column in dataframe.columns:\n",
    "        mean_list.append(dataframe[\"{}\".format(column)].mean())\n",
    "    return mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:36:48.104654Z",
     "start_time": "2021-08-23T03:36:47.862112Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the function to the ngram DataFrames\n",
    "pos_uni_tfidf_means_list = get_means(uni_tfidf_pos_df)\n",
    "pos_bi_tfidf_means_list = get_means(bi_tfidf_pos_df)\n",
    "pos_tri_tfidf_means_list = get_means(tri_tfidf_pos_df)\n",
    "\n",
    "# create DataFrame from the list of uni tfidf means\n",
    "pos_uni_tfidf_means_df = pd.DataFrame({\"Unigram\": uni_tfidf_pos_df.columns,\n",
    "                                  \"Mean\": pos_uni_tfidf_means_list})\n",
    "\n",
    "pos_bi_tfidf_means_df = pd.DataFrame({\"Bigram\": bi_tfidf_pos_df.columns,\n",
    "                                 \"Mean\": pos_bi_tfidf_means_list})\n",
    "\n",
    "pos_tri_tfidf_means_df = pd.DataFrame({\"Trigram\": tri_tfidf_pos_df.columns,\n",
    "                                      \"Mean\": pos_tri_tfidf_means_list})\n",
    "\n",
    "# get the top 14 weighted pos bigrams\n",
    "top_common_tfidf_pos_bi_means_df = pos_bi_tfidf_means_df[pos_bi_tfidf_means_df.Mean > 0.1]\n",
    "not_top_common_tfidf_pos_bi_means_df = pos_bi_tfidf_means_df[pos_bi_tfidf_means_df.Mean <=0.1]\n",
    "tfidf_bi_pos_to_remove = list(not_top_common_tfidf_pos_bi_means_df.Bigram)\n",
    "top_common_tfidf_bi_pos_df = bi_tfidf_pos_df.drop(tfidf_bi_pos_to_remove, axis=1)\n",
    "\n",
    "# get the top weighted pos trigrams\n",
    "top_common_tfidf_pos_tri_means_df = pos_tri_tfidf_means_df[pos_tri_tfidf_means_df.Mean > 0.05]\n",
    "not_top_common_tfidf_pos_tri_means_df = pos_tri_tfidf_means_df[pos_tri_tfidf_means_df.Mean <= 0.05]\n",
    "tfidf_tri_pos_to_remove = list(not_top_common_tfidf_pos_tri_means_df.Trigram)\n",
    "top_common_tfidf_tri_pos_df = tri_tfidf_pos_df.drop(tfidf_tri_pos_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T02:54:27.204609Z",
     "start_time": "2021-08-23T02:54:27.200803Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fce_df[\"Error_Rate\"] = fce_df.Number_of_Mistakes / fce_df.Number_of_Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Correction Codes Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:07:16.677636Z",
     "start_time": "2021-08-23T04:07:16.633952Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create correction code unigrams\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
    "X = vectorizer.fit_transform(fce_df[\"Correction_Codes\"])\n",
    "uni_correction_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Models\n",
    "\n",
    "Here I implement 3 different models that are differentiated by the target variable.\n",
    "\n",
    "**Model 1:** Uses the original raw answer scores from the .xml files.\n",
    "\n",
    "**Model 2:** Uses the answer score level. For example, 5.1, 5.2, and 5.3 and are all grouped into the same category, Level 5. Note that the lowest level includes 2.3 and below.\n",
    "\n",
    "**Model 3:** Uses the answer score quarter, i.e. the top 25% of answer scores, the second 25%, and so on.\n",
    "\n",
    "The best performing model is the one that attempts to predict the raw answer scores.\n",
    "\n",
    "**Training Set Accuracy: 39%**\n",
    "\n",
    "**Test Set Accuracy: 36%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:05:35.027649Z",
     "start_time": "2021-08-23T04:05:35.019930Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# base model\n",
    "# all model versions include the following variables\n",
    "# error rate\n",
    "# number of tokens\n",
    "# all 3 target variable versions\n",
    "base_model = pd.DataFrame(fce_df[\"Error_Rate\"])\n",
    "base_model = base_model.merge(fce_df[\"Number_of_Tokens\"], left_index=True, right_index=True)\n",
    "base_model = base_model.merge(fce_df[\"Answer_Score\"], left_index=True, right_index=True)\n",
    "base_model = base_model.merge(fce_df[\"Answer_Score_Level\"], left_index=True, right_index=True)\n",
    "base_model = base_model.merge(fce_df[\"Answer_Score_Quarter\"], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature Sets\n",
    "\n",
    "Various feature sets were created and processed through the models. In the end, the combination of the following was used:\n",
    "\n",
    "* Word uni and bigrams with TF-IDF (those above a certain mean for corpus)\n",
    "* Parts-of-Speech uni, bi, and trigrams with TF-IDF (those above a certain mean for corpus)\n",
    "* Correction code unigrams with TF-IDF\n",
    "* Error Rate\n",
    "* Number of tokens\n",
    "\n",
    "This brings our feature set to a total of 139."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:57:31.917435Z",
     "start_time": "2021-08-23T03:57:31.910586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# word uni and bigrams\n",
    "word_ngrams = base_model.merge(uni_word_df, left_index=True, right_index=True)\n",
    "word_ngrams = word_ngrams.merge(bi_word_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T03:57:32.250164Z",
     "start_time": "2021-08-23T03:57:32.241101Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# just the uni, bi, and trigram pos tags\n",
    "pos_ngrams = base_model.merge(uni_pos_df, left_index=True, right_index=True)\n",
    "pos_ngrams = pos_ngrams.merge(bi_pos_df, left_index=True, right_index=True)\n",
    "pos_ngrams = pos_ngrams.merge(tri_pos_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:07:23.950297Z",
     "start_time": "2021-08-23T04:07:23.944942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# just the unigrams from the correction codes\n",
    "correction_unigrams = base_model.merge(uni_correction_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:06:21.646739Z",
     "start_time": "2021-08-23T04:06:21.638361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tfidf uni and bi grams of words\n",
    "tfidf_word_ngrams = base_model.merge(top_common_tfidf_uni_word_df, left_index=True, right_index=True)\n",
    "tfidf_word_ngrams = tfidf_word_ngrams.merge(top_common_tfidf_bi_word_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:00:16.584878Z",
     "start_time": "2021-08-23T04:00:16.576394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tfidf uni, bi, and trigrams of pos\n",
    "tfidf_pos_ngrams = base_model.merge(uni_tfidf_pos_df, left_index=True, right_index=True)\n",
    "tfidf_pos_ngrams = tfidf_pos_ngrams.merge(top_common_tfidf_bi_pos_df, left_index=True, right_index=True)\n",
    "tfidf_pos_ngrams = tfidf_pos_ngrams.merge(top_common_tfidf_tri_pos_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:20:06.394981Z",
     "start_time": "2021-08-23T04:20:06.379956Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all of the features together (tfidf versions)\n",
    "tfidf_feature_set = base_model.merge(top_common_tfidf_uni_word_df, left_index=True, right_index=True)\n",
    "tfidf_feature_set = tfidf_feature_set.merge(top_common_tfidf_bi_word_df, left_index=True, right_index=True)\n",
    "tfidf_feature_set = tfidf_feature_set.merge(uni_tfidf_pos_df, left_index=True, right_index=True)\n",
    "tfidf_feature_set = tfidf_feature_set.merge(top_common_tfidf_bi_pos_df, left_index=True, right_index=True)\n",
    "tfidf_feature_set = tfidf_feature_set.merge(top_common_tfidf_tri_pos_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:23:18.659573Z",
     "start_time": "2021-08-23T04:23:18.657253Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_df = tfidf_pos_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Raw Answer Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:23:19.148074Z",
     "start_time": "2021-08-23T04:23:19.133500Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.3935213583188286\n",
      "\n",
      "Test set score: 0.3614643154331767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "Y = model_df['Answer_Score']\n",
    "X = np.array(model_df.drop(['Answer_Score',\n",
    "                            'Answer_Score_Level',\n",
    "                            'Answer_Score_Quarter'], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Answer Score Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:23:19.478186Z",
     "start_time": "2021-08-23T04:23:19.460849Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.34826925687479837\n",
      "\n",
      "Test set score: 0.30923561539264166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "Y = model_df['Answer_Score_Level']\n",
    "X = np.array(model_df.drop(['Answer_Score_Level', 'Answer_Score', 'Answer_Score_Quarter'], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Answer Score Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:23:21.696294Z",
     "start_time": "2021-08-23T04:23:21.680509Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.34405022715009637\n",
      "\n",
      "Test set score: 0.3000110179033092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "Y = model_df['Answer_Score_Quarter']\n",
    "X = np.array(model_df.drop(['Answer_Score_Quarter', 'Answer_Score', 'Answer_Score_Level'], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
